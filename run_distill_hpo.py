# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: run_distill_hpo.py
# Title: çŸ¥è­˜è’¸ç•™å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ (HPOå°‚ç”¨)
# Description: KnowledgeDistillationManagerã‚’ä½¿ç”¨ã—ã¦ã€çŸ¥è­˜è’¸ç•™ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™ã€‚
#
# ä¿®æ­£ (v17 - HPOæ­£å¸¸åŒ–):
# - v15(bias=0.1) ã¨ v16(bias=0.5) ã®ä¸¡æ–¹ã§ã€spike_reg_loss ãŒ 4.0 ã‚’
#   è¶…ãˆã‚‹ã€Œã‚¹ãƒ‘ã‚¤ã‚¯çˆ†ç™ºã€ãŒç™ºç”Ÿã—ã¦ã„ãŸã“ã¨ã‚’ç‰¹å®š (spike_rate ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯ãƒã‚°)ã€‚
# - bias=0.1 ã§ã‚‚å¼·ã™ããŸã¨åˆ¤æ–­ã—ã€å¼·åˆ¶ãƒã‚¤ã‚¢ã‚¹ã‚’ 0.01 ã«å¼•ãä¸‹ã’ã‚‹ã€‚
# - v_init=0.0 ã®å¼·åˆ¶ã¯ v15 ã‹ã‚‰ç¶­æŒã™ã‚‹ã€‚
#
# ã€!!! ã‚¹ãƒ‘ã‚¤ã‚¯æ¶ˆæ»… (spike_rate=0) ä¿®æ­£ v2 !!!ã€‘
# - v15 ã§è¿½åŠ ã•ã‚ŒãŸ L.171-181 ã®ã€Œv_init=0.0 ã®å¼·åˆ¶ã€ãŒã€
#   spiking_transformer_v2.py (L.49-57) ã®
#   ã€Œv_init ã‚’ v_threshold * 0.999 (0.4995) ã«è¨­å®šã™ã‚‹ã€
#   ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç„¡åŠ¹åŒ–ã—ã¦ã„ãŸã“ã¨ãŒåŸå› ã¨ç‰¹å®šã€‚
# - L.171-181 ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã€ãƒ¢ãƒ‡ãƒ«å´ã®
#   v_init è‡ªå‹•è¨­å®šãƒ­ã‚¸ãƒƒã‚¯ã‚’å¾©æ´»ã•ã›ã‚‹ã€‚
#
# ã€!!! MemoryModule.__init__ got unexpected keyword argument 'v_threshold' ä¿®æ­£ v9 (å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¼•æ•°ã®å¼·åˆ¶å‰Šé™¤) !!!ã€‘
# - ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ãŒ 'self' ä»¥å¤–ã®å¼•æ•°ã‚’æœŸå¾…ã—ã¦ã„ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€
#   DIã‚³ãƒ³ãƒ†ãƒŠãŒè¨­å®šã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã—ã¦ã„ã‚‹å•é¡Œã‚’ä¿®æ­£ã€‚
# - ãƒ¢ãƒ‡ãƒ«è¨­å®šå…¨ä½“ã‚’å–å¾—ã—ã€'neuron' ã‚µãƒ–è¨­å®šã‹ã‚‰ã€å•é¡Œã®åŸå› ã¨ãªã£ã¦ã„ã‚‹ã™ã¹ã¦ã®å¼•æ•°ã‚’ pop() ã§å‰Šé™¤ã—ãŸå¾Œã€
#   è¦ªã®ConfigurationProviderã« from_dict() ã§å†ãƒã‚¤ãƒ³ãƒ‰ã™ã‚‹ã“ã¨ã§è¨­å®šã‚’å¼·åˆ¶çš„ã«æ›´æ–°ã™ã‚‹ã€‚

import argparse
import asyncio
import torch
import torchvision.models as models  # type: ignore[import-untyped]
from torch.utils.data import DataLoader
from omegaconf import OmegaConf, DictConfig
from typing import Any, List, Optional, cast, Dict
import sys 
import os

# --- â–¼â–¼â–¼ ã€!!! ä¿®æ­£ (HSEO module not found) !!!ã€‘ â–¼â–¼â–¼
# sys.path ã®ä¿®æ­£ã‚’ã€app.containers ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚ˆã‚Š *å‰* ã«ç§»å‹•ã™ã‚‹
project_root: str = os.path.abspath(os.path.dirname(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)
# --- â–²â–²â–² ã€!!! ä¿®æ­£ !!!ã€‘ â–²â–²â–²


# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ  (run_hpo.py ã¨åŒã˜ä¿®æ­£)
# project_root: str = os.path.abspath(os.path.dirname(__file__)) # å‰Šé™¤ (ä¸Šã«ç§»å‹•)
# if project_root not in sys.path: # å‰Šé™¤
#     sys.path.insert(0, project_root) # å‰Šé™¤

# --- â–¼â–¼â–¼ ã€æœ€å„ªå…ˆè¿½åŠ ã€‘ç¾åœ¨ã®å®Ÿè¡Œãƒ‘ã‚¹ã‚’ãƒ­ã‚°ã«å‡ºåŠ› (ç’°å¢ƒä¸æ•´åˆã®ç¢ºèªç”¨) â–¼â–¼â–¼ ---
print(f"ğŸš¨ DEBUG: Currently executing script from: {os.path.abspath(__file__)}")
# --- â–²â–²â–² ã€æœ€å„ªå…ˆè¿½åŠ ã€‘ â–²â–²â–² ---

from app.containers import TrainingContainer
from snn_research.distillation.knowledge_distillation_manager import KnowledgeDistillationManager
from snn_research.benchmark import TASK_REGISTRY


async def main() -> None:
    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ç”¨ã®å¤‰æ•° (try/exceptãƒ–ãƒ­ãƒƒã‚¯ã®å¤–å´ã§å®šç¾©)
    # NOTE: ã“ã‚Œã‚‰ã®å¤‰æ•°ã¯ aggressive_init ã®ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£ã§åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚
    DEBUG_LR_VALUE: float = 0.0
    DEBUG_SPIKE_REG_VALUE: float = 0.0
    DEBUG_V_THRESHOLD_VALUE: float = 0.0
    DEBUG_V_RESET_VALUE: float = 0.0
    DEBUG_V_DECAY_VALUE: float = 0.0
    DEBUG_BIAS_VALUE: float = 0.0 # ãƒ¢ãƒ‡ãƒ«ãƒã‚¤ã‚¢ã‚¹æ³¨å…¥ç”¨
    DEBUG_V_INIT_VALUE_FORCED: float = 0.0 # åˆæœŸé›»ä½æ³¨å…¥ç”¨

    parser = argparse.ArgumentParser(description="SNN Knowledge Distillation Runner")
    parser.add_argument("--config", type=str, default="configs/base_config.yaml", help="Base config file path")
    parser.add_argument("--model_config", type=str, default="configs/models/spiking_transformer.yaml", help="SNN model architecture config file path")
    parser.add_argument("--task", type=str, default="cifar10", help="The benchmark task to distill.")
    parser.add_argument("--teacher_model", type=str, default="resnet18", help="The torchvision teacher model to use.")
    parser.add_argument("--epochs", type=int, default=15, help="Number of distillation epochs.")
    parser.add_argument(
        "--override_config",
        type=str,
        action='append',
        help="Override config (e.g., 'training.epochs=5')"
    )
    args = parser.parse_args()

    # --- â–¼â–¼â–¼ NameError ä¿®æ­£: containerã®åˆæœŸåŒ–ã‚’å†é…ç½® â–¼â–¼â–¼ ---
    container = TrainingContainer()
    # --- â–²â–²â–² NameError ä¿®æ­£ â–²â–²â–² ---
    
    # 2. åŸºæœ¬è¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰
    container.config.from_yaml(args.config)

    # --- â–¼â–¼â–¼ ã€!!! ã‚¨ãƒ©ãƒ¼ä¿®æ­£ (tokenizer_name is None) v2 !!!ã€‘ â–¼â–¼â–¼
    # 2.5. ãƒ‡ãƒ¼ã‚¿è¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰
    # --task "cifar10" ã«åŸºã¥ãã€"configs/data/cifar10.yaml" ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    
    # project_root (L.17ã§å®šç¾©æ¸ˆã¿) ã‚’åŸºæº–ã«çµ¶å¯¾ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹
    data_config_path = os.path.join(project_root, f"configs/data/{args.task}.yaml")

    if os.path.exists(data_config_path):
        print(f"INFO: Loading data config: {data_config_path}")
        container.config.from_yaml(data_config_path)
    else:
        # ã©ã®ãƒ‘ã‚¹ã‚’æ¢ã—ã«è¡Œã£ãŸã‹æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã€çµ¶å¯¾ãƒ‘ã‚¹ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
        print(f"WARNING: Data config file not found at: {data_config_path}. 'data' config might be incomplete.")
    # --- â–²â–²â–² ã€!!! ã‚¨ãƒ©ãƒ¼ä¿®æ­£ v2 !!!ã€‘ â–²â–²â–²

    # 3. ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰ 
    try:
        # --- â–¼ ä¿®æ­£ (v_hpo_fix_3): ãƒ­ãƒ¼ãƒ‰ãƒ­ã‚¸ãƒƒã‚¯ã®ä¿®æ­£ â–¼ ---
        cfg_raw = OmegaConf.load(args.model_config)
        
        if isinstance(cfg_raw, DictConfig) and 'model' in cfg_raw:
            container.config.model.from_dict(
                cast(Dict[str, Any], OmegaConf.to_container(cfg_raw.model, resolve=True))
            )
        elif isinstance(cfg_raw, DictConfig):
            model_config_dict = OmegaConf.to_container(cfg_raw, resolve=True)
            if isinstance(model_config_dict, dict):
                container.config.from_dict({'model': model_config_dict})
            else:
                 raise TypeError(f"Model config loaded from {args.model_config} is not a dictionary.")
        else:
             raise TypeError(f"Model config loaded from {args.model_config} is not a dictionary.")
            
    except Exception as e:
        print(f"Warning: Could not load or merge model config '{args.model_config}': {e}")
        container.config.from_dict({'model': {}})


    # 4. ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰ã‚¨ãƒãƒƒã‚¯æ•°ã‚’ä¸Šæ›¸ã
    container.config.training.epochs.from_value(args.epochs)
    
    # 5. HPOã‹ã‚‰ã® --override_config ã‚’é©ç”¨
    if args.override_config:
        print(f"Applying {len(args.override_config)} overrides from command line...")
        for override in args.override_config:
            try:
                keys, value_str = override.split('=', 1)
                value: Any
                try:
                    value = int(value_str)
                except ValueError:
                    try:
                        value = float(value_str)
                    except ValueError:
                        if value_str.lower() == 'true':
                            value = True
                        elif value_str.lower() == 'false':
                            value = False
                        else:
                            value = value_str

                key_parts = keys.split('.')
                config_provider = container.config
                for part in key_parts:
                    config_provider = getattr(config_provider, part)
                
                config_provider.from_value(value)
                print(f"  - Applied: {keys} = {value}")
            except Exception as e:
                print(f"Error applying override '{override}': {e}")
    
    
    # --- â–¼â–¼â–¼ ã€ãƒ‡ãƒãƒƒã‚°å¼·åˆ¶ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã®å¾©æ´»ã¨å†å°å…¥ã€‘ â–¼â–¼â–¼ ---

    # 6. ã€ãƒ‡ãƒãƒƒã‚°å¾©æ´»ã€‘ spike_reg_weight ã‚’å¼·åˆ¶çš„ã«ä½ã„å€¤ã«å›ºå®š
    # try:
    #     config_provider = container.config.training.gradient_based.distillation.loss.spike_reg_weight
    #     DEBUG_SPIKE_REG_VALUE = 1e-6 
    #     config_provider.from_value(DEBUG_SPIKE_REG_VALUE)
    #     print(f"  - ã€DEBUG OVERRIDEã€‘ Forced spike_reg_weight to: {DEBUG_SPIKE_REG_VALUE}")
    # except Exception as e:
    #     print(f"Warning: Could not force spike_reg_weight. This may cause spike_rate=0: {e}")
        
    # 7. ã€ãƒ‡ãƒãƒƒã‚°å¾©æ´»ã€‘ learning_rate ã‚’å¼·åˆ¶çš„ã«é«˜ãè¨­å®š
    # try:
    #     config_provider_lr = container.config.training.gradient_based.learning_rate
    #     DEBUG_LR_VALUE = 1e-2 # ä»¥å‰ã®ä¿®æ­£ã‚’å¾©æ´» (1e-2)
    #     config_provider_lr.from_value(DEBUG_LR_VALUE)
    #     print(f"  - ã€DEBUG OVERRIDEã€‘ Forced learning_rate to: {DEBUG_LR_VALUE}")
    # except Exception as e:
    #     print(f"Warning: Could not force learning_rate: {e}")

    # 8. ã€ãƒ‡ãƒãƒƒã‚°å¾©æ´»ã€‘ V_THRESHOLD ã‚’å¼·åˆ¶çš„ã«è¨­å®š (â€»ã“ã‚Œã¯HPOå¯¾è±¡å¤–ãªã®ã§æ®‹ã—ã¦ã‚‚OK)
    try:
        config_provider_v_th = container.config.model.neuron.v_threshold
        DEBUG_V_THRESHOLD_VALUE = 0.5 
        if config_provider_v_th() < 1e-5:
            config_provider_v_th.from_value(DEBUG_V_THRESHOLD_VALUE)
            print(f"  - ã€DEBUG OVERRIDEã€‘ Forced V_THRESHOLD to: {DEBUG_V_THRESHOLD_VALUE}")
        else:
             DEBUG_V_THRESHOLD_VALUE = config_provider_v_th()
    except Exception as e:
        print(f"Warning: Could not force V_THRESHOLD: {e}")
    
    # 9. ã€ãƒ‡ãƒãƒƒã‚°å¾©æ´»ã€‘ v_reset ã‚’å¼·åˆ¶çš„ã« 0.0 ã«è¨­å®š (ã‚¼ãƒ­ãƒªã‚»ãƒƒãƒˆå›ºå®š)
    # try:
    #     config_provider_v_reset = container.config.model.neuron.v_reset
    #     DEBUG_V_RESET_VALUE = 0.0 
    #     config_provider_v_reset.from_value(DEBUG_V_RESET_VALUE)
    #     print(f"  - ã€DEBUG OVERRIDEã€‘ Forced v_reset to: {DEBUG_V_RESET_VALUE}")
    # except Exception as e:
    #     print(f"Warning: Could not force v_reset: {e}")

    # 10. ã€ãƒ‡ãƒãƒƒã‚°å¾©æ´»ã€‘ v_decay ã‚’å¼·åˆ¶çš„ã« 0.999 ã«è¨­å®š
    # try:
    #     config_provider_v_decay = container.config.model.neuron.v_decay
    #     DEBUG_V_DECAY_VALUE = 0.999 
    #     config_provider_v_decay.from_value(DEBUG_V_DECAY_VALUE)
    #     print(f"  - ã€DEBUG OVERRIDEã€‘ Forced v_decay to: {DEBUG_V_DECAY_VALUE}")
    # except Exception as e:
    #     print(f"Warning: Could not force v_decay: {e}")

    # --- â–¼â–¼â–¼ ä¿®æ­£ (spike_rate=0 ä¿®æ­£ v2): v_init=0.0 ã®å¼·åˆ¶ã‚’ *ç„¡åŠ¹åŒ–* â–¼â–¼â–¼ ---
    # 10.5. ã€ãƒ‡ãƒãƒƒã‚°ç„¡åŠ¹åŒ– (v15)ã€‘ v_init ã‚’å¼·åˆ¶çš„ã« 0.0 ã«è¨­å®š
    # v14 (bias=0.1) ãŒ v_init=0.4995 ã‚’è‡ªå‹•è¨­å®šã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’
    # ç„¡åŠ¹åŒ–ã™ã‚‹ãŸã‚ã€v_init ã¯ 0.0 ã«æ˜ç¤ºçš„ã«å›ºå®šã™ã‚‹ã€‚
    # try:
    #     config_provider_v_init = container.config.model.neuron.v_init
    #     DEBUG_V_INIT_VALUE = 0.0 
    #     config_provider_v_init.from_value(DEBUG_V_INIT_VALUE)
    #     print(f"  - ã€DEBUG OVERRIDE (v15)ã€‘ Forced v_init to: {DEBUG_V_INIT_VALUE}")
    # except Exception as e:
    #     print(f"Warning: Could not force v_init: {e}")
    print(f"  - ã€INFO (spike_rate=0 fix v2)ã€‘ 'v_init=0.0' override is DISABLED.")
    print(f"  - ã€INFO (spike_rate=0 fix v2)ã€‘ Model will use internal logic (bias -> v_init=0.4995).")
    # --- â–²â–²â–² ä¿®æ­£ (spike_rate=0 ä¿®æ­£ v2) â–²â–²â–² ---

    # 11. ã€ãƒ‡ãƒãƒƒã‚°å¾©æ´»ã€‘ bias ã‚’å¼·åˆ¶çš„ã« 0.01 ã«è¨­å®š (ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤ãƒã‚¤ã‚¢ã‚¹)
    try:
        config_provider_bias = container.config.model.neuron.bias
        # --- â–¼â–¼â–¼ ä¿®æ­£ (v17): 0.5 -> 0.01 ã«å¼•ãä¸‹ã’ â–¼â–¼â–¼ ---
        DEBUG_BIAS_VALUE = 0.01  # 0.5 ã‹ã‚‰ 0.01 ã«å¤‰æ›´
        # --- â–²â–²â–² ä¿®æ­£ (v17) â–²â–²â–² ---
        
        # --- â–¼â–¼â–¼ ä¿®æ­£ (v14/v15): ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’ *å¾©æ´»* ã•ã›ã‚‹ â–¼â–¼â–¼ ---
        config_provider_bias.from_value(DEBUG_BIAS_VALUE)
        print(f"  - ã€DEBUG OVERRIDEã€‘ Forced neuron bias to: {DEBUG_BIAS_VALUE}")
    except Exception as e:
        print(f"Warning: Could not force neuron bias: {e}")
    # --- â–²â–²â–² ã€ãƒ‡ãƒãƒƒã‚°å¼·åˆ¶ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã®å¾©æ´»ã¨å†å°å…¥ã€‘ â–²â–²â–² ---
        

    # --- â–¼ ä¿®æ­£ (v_hpo_fix_tensor_size_mismatch) â–¼ ---
    if args.task == 'cifar10':
        print("INFO: Overriding data/model config for CIFAR-10 (img_size=32, patch_size=4).")
        
        try:
            container.config.model.img_size.from_value(32)
            container.config.model.patch_size.from_value(4)
        except Exception as e:
            print(f"Warning: Could not override config.model: {e}")

        try:
            if container.config.data.img_size.provided:
                container.config.data.img_size.from_value(32)
            else:
                container.config.data.from_dict({'img_size': 32})
                
            if container.config.data.patch_size.provided:
                container.config.data.patch_size.from_value(4)
            else:
                container.config.data.from_dict({'patch_size': 4})
                
        except Exception as e:
            print(f"Warning: Could not override config.data: {e}")


    # DIã‚³ãƒ³ãƒ†ãƒŠã‹ã‚‰å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æ­£ã—ã„é †åºã§å–å¾—ãƒ»æ§‹ç¯‰
    device = container.device()

    # --- â–¼â–¼â–¼ ã€ã‚¨ãƒ©ãƒ¼ä¿®æ­£ (MemoryModule.__init__ got unexpected keyword argument 'v_threshold') v9 (ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¼•æ•°ã®å¼·åˆ¶å‰Šé™¤) ã€‘ â–¼â–¼â–¼ ---
    # MemoryModule.__init__ ãŒ 'self' ä»¥å¤–ã®å¼•æ•°ã‚’å–ã‚‰ãªã„ãŸã‚ã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³è¨­å®šã‹ã‚‰å…¨ã¦ã®ä¸è¦ãªå¼•æ•°ã‚’å‰Šé™¤ã™ã‚‹ã€‚
    try:
        model_config_provider = container.config.model 
        raw_model_config = model_config_provider()

        # 1. è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å®‰å…¨ã« Python ã® dict ã«å¤‰æ›
        if OmegaConf.is_config(raw_model_config):
            clean_model_config = cast(Dict[str, Any], OmegaConf.to_container(raw_model_config, resolve=True))
        elif isinstance(raw_model_config, dict):
            clean_model_config = raw_model_config.copy()
            print("  - ã€DEBUG INFO v7ã€‘ Model config is already a raw dict (Likely from previous HPO run). Using copy for cleanup.")
        else:
             raise TypeError(f"Model config has unexpected type: {type(raw_model_config)}")
        
        # 2. 'neuron' ã‚µãƒ–è¨­å®šã‹ã‚‰ã€MemoryModuleãŒäºˆæœŸã—ãªã„å…¨ã¦ã®å¼•æ•°ã‚’å‰Šé™¤ã™ã‚‹
        if 'neuron' in clean_model_config:
            neuron_config = clean_model_config['neuron']
            deleted_keys: List[str] = []
            
            # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¯ãƒ©ã‚¹ãŒå—ã‘ä»˜ã‘ãªã„å¼•æ•°ãƒªã‚¹ãƒˆ (ãƒ­ã‚°ã‚ˆã‚Šæ¨æ¸¬)
            keys_to_remove = [
                'type', # ä»¥å‰ã®ä¿®æ­£å¯¾è±¡
                'v_threshold', 
                'threshold_decay', 
                'threshold_step', 
                'bias', 
                'v_init', 
                'bias_init',
                # 'features' ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚µã‚¤ã‚ºãªã®ã§æ®‹ã—ã¦ãŠãã¹ãã ãŒã€å¿µã®ç‚ºãƒ­ã‚°ã«æ®‹ã™
                # 'features' 
            ]

            for key in keys_to_remove:
                if key in neuron_config:
                    neuron_config.pop(key)
                    deleted_keys.append(key)
            
            if deleted_keys:
                # 3. ä¿®æ­£ã•ã‚ŒãŸè¾æ›¸ã§ã‚³ãƒ³ãƒ†ãƒŠã®è¨­å®šã‚’ä¸Šæ›¸ã (modelå…¨ä½“ã‚’ from_dict ã§ä¸Šæ›¸ã)
                model_config_provider.from_dict(clean_model_config) 
                print(f"  - ã€DEBUG FIX v9ã€‘ Cleaned neuron config. Removed keys: {', '.join(deleted_keys)} and forcefully re-bound model config.")
            else:
                 print(f"  - ã€DEBUG INFO v9ã€‘ No problematic keys found in model.neuron config. Proceeding.")
                 
        else:
             print("  - ã€DEBUG INFO v9ã€‘ 'neuron' key not found in model config. Skipping neuron cleanup.")
             
    except Exception as e:
        print(f"Warning: Failed to clean neuron config before model instantiation (v9): {e}")
    # --- â–²â–²â–² ã€ã‚¨ãƒ©ãƒ¼ä¿®æ­£ v9ã€‘ â–²â–²â–² ---


    # ssn_core.py å´ã§ vocab_size ã‚’å‡¦ç†ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã—ãŸãŸã‚ã€ã“ã“ã¯å¤‰æ›´ä¸è¦
    student_model = container.snn_model(vocab_size=10).to(device)
    
    # --- â–¼â–¼â–¼ ã€!!! HPOä¿®æ­£ (v16): aggressive_init ã¯ *ç„¡åŠ¹* ã®ã¾ã¾ !!!ã€‘ â–¼â–¼â–¼ ---
    
    # V_INITã®å¼·åˆ¶è¨­å®š (ç„¡åŠ¹åŒ–ã®ã¾ã¾)
    # DEBUG_V_INIT_VALUE_FORCED = 0.499 # åˆæœŸé›»ä½ã®ãƒ‡ãƒãƒƒã‚°å€¤ã‚’å¾©æ´»
    
    def aggressive_init(m: torch.nn.Module):
        """ (v16: ã“ã®é–¢æ•°ã¯å‘¼ã³å‡ºã•ã‚Œãªã„) """
        # NOTE: DEBUG_BIAS_VALUE ã¯ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£ã§å‚ç…§ã•ã‚Œã¾ã™ã€‚
        if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):
            # Glorot (Xavier) Uniform initializationã‚’é©ç”¨
            torch.nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                # ã€ä¿®æ­£: v16 (v14) ã§ 0.0 (æ¨™æº–) ã«æˆ»ã™ã€‘
                torch.nn.init.constant_(m.bias, 0.0) 
                # print(f"  - INJECTED BIAS: {DEBUG_BIAS_VALUE} for {m.__class__.__name__}")
    
    print("INFO: Using standard weight initialization (Forced neuron bias is ENABLED via config).")
    # --- â–¼â–¼â–¼ ä¿®æ­£ (v16): ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ (ç„¡åŠ¹åŒ–) ã®ã¾ã¾ â–¼â–¼â–¼ ---
    # student_model.apply(aggressive_init) # (v16: ç„¡åŠ¹åŒ–)
    # --- â–²â–²â–² ä¿®æ­£ (v16) â–²â–²â–² ---
    
    # --- V_INITã®å¼·åˆ¶è¨­å®š (ç„¡åŠ¹åŒ–ã®ã¾ã¾) ---
    # try:
    #     print(f"ğŸ§  DEBUG: Setting initial membrane potential (V_init) to: {DEBUG_V_INIT_VALUE_FORCED} (V_TH=0.5)")
    #     for name, module in student_model.named_modules():
    #         if hasattr(module, 'v_init'):
    #              # type: ignore[attr-defined]
    #             module.v_init = DEBUG_V_INIT_VALUE_FORCED # type: ignore[attr-defined] 
    # except Exception as e:
    #     print(f"Warning: Could not set V_init on all neurons: {e}")
    
    # --- â–²â–²â–² ã€!!! HPOä¿®æ­£ (v16) !!!ã€‘ â–²â–²â–² ---
    
    optimizer = container.optimizer(params=student_model.parameters())
    scheduler = container.scheduler(optimizer=optimizer) if container.config.training.gradient_based.use_scheduler() else None

    # --- æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ ---
    print(f"ğŸ§  Initializing ANN teacher model ({args.teacher_model})...")
    if args.teacher_model == "resnet18":
        teacher_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
        num_ftrs = teacher_model.fc.in_features
        teacher_model.fc = torch.nn.Linear(num_ftrs, 10)
    else:
        raise ValueError(f"Unsupported teacher model: {args.teacher_model}")
    teacher_model = teacher_model.to(device)
    teacher_model.eval()

    distillation_trainer = container.distillation_trainer(
        model=student_model,
        optimizer=optimizer,
        scheduler=scheduler,
        device=device,
        rank=-1
    )
    model_registry = container.model_registry()

    # --- â–¼ ä¿®æ­£ (v_hpo_fix_attr_error): dict ã‚’ DictConfig ã«å¤‰æ› â–¼ ---
    manager_config_dict: Dict[str, Any] = container.config()
    manager_config_omegaconf: DictConfig = OmegaConf.create(manager_config_dict)

    manager = KnowledgeDistillationManager(
        student_model=student_model,
        teacher_model=teacher_model,
        trainer=distillation_trainer,
        tokenizer_name=container.config.data.tokenizer_name(),
        model_registry=model_registry,
        device=device,
        config=manager_config_omegaconf
    )
    # --- â–² ä¿®æ­£ (v_hpo_fix_attr_error) â–² ---

    # --- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ ---
    TaskClass = TASK_REGISTRY.get(args.task)
    if not TaskClass:
        raise ValueError(f"Task '{args.task}' not found.")
        
    # --- â–¼ ä¿®æ­£ (v_hpo_fix_type_error): img_size ã‚’ __init__ ã«æ¸¡ã™ â–¼ ---
    task_init_kwargs: Dict[str, Any] = {
        "tokenizer": container.tokenizer(),
        "device": device,
        "hardware_profile": {}
    } 
    if args.task == 'cifar10':
        task_init_kwargs['img_size'] = container.config.data.img_size()

    task = TaskClass(**task_init_kwargs)
    # --- â–² ä¿®æ­£ (v_hpo_fix_type_error) â–² ---
    
    
    # --- â–¼ ä¿®æ­£(v_hpo_fix_type_error): kwargs ã‚’å‰Šé™¤ â–¼ ---
    train_dataset, val_dataset = task.prepare_data(data_dir="data")
    # --- â–² ä¿®æ­£(v_hpo_fix_type_error) â–² ---

    # çŸ¥è­˜è’¸ç•™ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ©ãƒƒãƒ—
    # --- â–¼ ä¿®æ­£ (v_async_fix): await ã‚’è¿½åŠ  â–¼ ---
    train_loader, val_loader = await manager.prepare_dataset(
        train_dataset=train_dataset,
        val_dataset=val_dataset,
        collate_fn=task.get_collate_fn(),
        batch_size=container.config.training.batch_size()
    )
    # --- â–² ä¿®æ­£ (v_async_fix) â–² ---
    
    # --- â–¼â–¼â–¼ ç’°å¢ƒæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯: ã‚³ã‚¢ä¿®æ­£ã®ç¢ºèªã¨ãƒ‡ãƒãƒƒã‚°å€¤ã®è¡¨ç¤º â–¼â–¼â–¼ ---
    CORE_TAU_MEM_VALUE = "NOT FOUND"
    try:
        for name, module in student_model.named_modules():
            if 'BioLIFNeuron' in module.__class__.__name__ and hasattr(module, 'tau_mem'):
                CORE_TAU_MEM_VALUE = str(getattr(module, 'tau_mem'))
                break 
    except Exception as e:
        CORE_TAU_MEM_VALUE = f"Error: {e}"
        
    print("\n=============================================")
    print("ğŸš¨ FINAL DEBUG CHECK (RE-FORCED PARAMETERS) ğŸš¨")
    print(f"  V_THRESHOLD (HPO/YAML): {container.config.model.neuron.v_threshold()}")
    print(f"  LR (HPO/YAML): {container.config.training.gradient_based.learning_rate()}")
    print(f"  SPIKE_REG_W (HPO/YAML): {container.config.training.gradient_based.distillation.loss.spike_reg_weight()}")
    
    print("--- FORCED VALUES (v12: Most should be DISABLED) ---")
    # print(f"  LR (Forced): {DEBUG_LR_VALUE}") # ç„¡åŠ¹åŒ–
    # print(f"  V_THRESHOLD (Forced): {DEBUG_V_THRESHOLD_VALUE}") # v_threshold ã¯æ®‹ã™
    # print(f"  V_RESET (Forced): {DEBUG_V_RESET_VALUE}") # ç„¡åŠ¹åŒ–
    # print(f"  V_DECAY (Forced): {DEBUG_V_DECAY_VALUE}") # ç„¡åŠ¹åŒ–
    # print(f"  NEURON_BIAS (Forced): {DEBUG_BIAS_VALUE} (Config Override)") # ç„¡åŠ¹åŒ–
    # print(f"  LAYER_BIAS (Injected): {DEBUG_BIAS_VALUE} (Direct Weight Init)") # ç„¡åŠ¹åŒ–
    
    print("--- STRUCTURAL FIX CHECK ---")
    # print(f"  V_INIT (Forced): {DEBUG_V_INIT_VALUE_FORCED}") # ç„¡åŠ¹åŒ–
    print(f"  CORE_TAU_MEM (Hardcoded in LIF.py): {CORE_TAU_MEM_VALUE}")
    print("=============================================\n")
    # --- â–²â–²â–² ç’°å¢ƒæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ â–²â–²â–² ---

    # è’¸ç•™ã®å®Ÿè¡Œ
    await manager.run_distillation(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=container.config.training.epochs(), # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å–å¾—
        model_id=f"{args.task}_distilled_from_{args.teacher_model}",
        task_description=f"An expert SNN for {args.task}, distilled from {args.teacher_model}.",
        # ä¿®æ­£ (v_hpo_config_fix): ã‚³ãƒ³ãƒ†ãƒŠã‹ã‚‰å–å¾—ã—ãŸ OmegaConf ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€
        # æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«è¨­å®š (model) ã‚’ç¢ºå®Ÿã«ãƒ—ãƒ¬ãƒ¼ãƒ³ãª Python è¾æ›¸ã¨ã—ã¦æŠ½å‡ºã™ã‚‹ã€‚
        student_config=cast(Dict[str, Any], OmegaConf.to_container(manager_config_omegaconf.model, resolve=True))
    )

if __name__ == "__main__":
    asyncio.run(main())
