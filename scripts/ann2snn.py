# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/ann2snn.py
# (æ”¹ä¿®)
#
# Title: ANN-SNN å¤‰æ› å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#
# Description:
# doc/SNNé–‹ç™ºï¼šåŸºæœ¬è¨­è¨ˆæ€æƒ³.md (ã‚»ã‚¯ã‚·ãƒ§ãƒ³6.3) ã«åŸºã¥ãã€
# 1. ANNãƒ¢ãƒ‡ãƒ« (SimpleCNN) ã‚’CIFAR-10ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ã€
# 2. è¨“ç·´æ¸ˆã¿ANNãƒ¢ãƒ‡ãƒ«ã‚’ SNNãƒ¢ãƒ‡ãƒ« (SpikingCNN) ã«å¤‰æ›ã—ã€
# 3. å¤‰æ›å¾Œã®SNNãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è©•ä¾¡ã™ã‚‹ã€
# ã¨ã„ã†ä¸€é€£ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
#
# æ”¹å–„ (v2):
# - mypy --strict æº–æ‹ ã®ãŸã‚ã®å‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ ã€‚
# - printæ–‡ã‚’ logging ã«ç½®ãæ›ãˆã€‚

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms # type: ignore[import-untyped]
from torch.utils.data import DataLoader
import sys
from pathlib import Path
import logging # â—¾ï¸â—¾ï¸â—¾ï¸ è¿½åŠ  â—¾ï¸â—¾ï¸â—¾ï¸
from typing import Dict, Any, cast, Tuple # â—¾ï¸â—¾ï¸â—¾ï¸ è¿½åŠ  â—¾ï¸â—¾ï¸â—¾ï¸

sys.path.append(str(Path(__file__).resolve().parent.parent))

from snn_research.benchmark.ann_baseline import SimpleCNN
from snn_research.conversion.ann_to_snn_converter import ANNToSNNConverter
from snn_research.core.snn_core import SpikingCNN # å¤‰æ›å¾Œã®SNNãƒ¢ãƒ‡ãƒ«
from snn_research.core.neurons import AdaptiveLIFNeuron
from spikingjelly.activation_based import functional as SJ_F # type: ignore[import-untyped]

# --- â–¼ ä¿®æ­£: ãƒ­ã‚¬ãƒ¼è¨­å®š â–¼ ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
# --- â–² ä¿®æ­£ â–² ---

# --- â–¼ ä¿®æ­£: å‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ  â–¼ ---
def train_ann(
    model: nn.Module, 
    device: torch.device, 
    train_loader: DataLoader, 
    optimizer: optim.Optimizer, 
    epoch: int
) -> None:
# --- â–² ä¿®æ­£ â–² ---
    model.train()
    criterion = nn.CrossEntropyLoss()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % 100 == 0:
            logger.info(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ' # type: ignore[arg-type]
                        f'({100. * batch_idx / len(train_loader):.0f}%)]\tLoss: {loss.item():.6f}')

# --- â–¼ ä¿®æ­£: å‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ  â–¼ ---
def evaluate_snn(
    model: nn.Module, 
    device: torch.device, 
    test_loader: DataLoader, 
    time_steps: int
) -> float:
# --- â–² ä¿®æ­£ â–² ---
    model.eval()
    correct: int = 0
    total: int = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            
            # SNNè©•ä¾¡ (SpikingCNNã¯å†…éƒ¨ã§Tã‚¹ãƒ†ãƒƒãƒ—ãƒ«ãƒ¼ãƒ—)
            SJ_F.reset_net(model)
            # SpikingCNNã¯ (logits, avg_spikes, mem) ã‚’è¿”ã™
            outputs, _, _ = model(input_images=data) # type: ignore[operator]
            
            # æœ€çµ‚çš„ãªãƒ­ã‚¸ãƒƒãƒˆ (æ™‚é–“å¹³å‡æ¸ˆã¿)
            final_logits: torch.Tensor = outputs
            
            pred = final_logits.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)

    accuracy = 100. * correct / total
    return accuracy

def main() -> None:
    # --- 1. æº–å‚™ ---
    use_cuda: bool = torch.cuda.is_available()
    device: torch.device = torch.device("cuda" if use_cuda else "cpu")
    logger.info(f"Using device: {device}")

    # CIFAR-10 ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    
    train_loader: DataLoader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
    test_loader: DataLoader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)

    # --- 2. ANNãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨è¨“ç·´ ---
    logger.info("--- 1. ANN Training ---")
    ann_model: SimpleCNN = SimpleCNN(num_classes=10).to(device)
    optimizer: optim.Optimizer = optim.Adam(ann_model.parameters(), lr=0.001)
    
    ann_epochs: int = 3 # ç°¡æ˜“çš„ãªè¨“ç·´
    for epoch in range(1, ann_epochs + 1):
        train_ann(ann_model, device, train_loader, optimizer, epoch)
    
    ann_model.eval()
    logger.info("âœ… ANN training complete.")

    # --- 3. ANN-SNN å¤‰æ› ---
    logger.info("--- 2. ANN-to-SNN Conversion ---")
    
    # å¤‰æ›å¾Œã®SNNãƒ¢ãƒ‡ãƒ«ï¼ˆSpikingCNNï¼‰ã®è¨­å®š
    time_steps: int = 16
    neuron_config: Dict[str, Any] = {
        'type': 'lif',
        'tau_mem': 10.0,
        'base_threshold': 1.0 # é–¾å€¤ã¯å¤‰æ›æ™‚ã«èª¿æ•´ã•ã‚Œã‚‹
    }
    
    # å¤‰æ›å¾Œã®SNNãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ– (é‡ã¿ã¯ãƒ€ãƒŸãƒ¼)
    # vocab_size=10 (num_classes)
    snn_model_skel: SpikingCNN = SpikingCNN(vocab_size=10, time_steps=time_steps, neuron_config=neuron_config)
    
    # å¤‰æ›å™¨ã®åˆæœŸåŒ–ã¨å®Ÿè¡Œ
    # ANNãƒ¢ãƒ‡ãƒ«ã®ReLUã‚’SNNã®LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«ãƒãƒƒãƒ”ãƒ³ã‚°
    converter = ANNToSNNConverter(
        ann_model=ann_model, 
        snn_model_skeleton=snn_model_skel,
        input_shape=(1, 3, 32, 32) # CIFAR-10ã®å…¥åŠ›å½¢çŠ¶
    )
    
    logger.info("Normalizing ANN weights (data-based)...")
    # (ç°¡æ˜“çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã§æ­£è¦åŒ–)
    converter.normalize_weights(data_loader=train_loader) 
    
    logger.info("Converting ANN model to SNN...")
    snn_model: nn.Module = converter.convert()
    snn_model = snn_model.to(device)
    logger.info("âœ… ANN-SNN conversion complete.")

    # --- 4. SNNãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ ---
    logger.info("--- 3. SNN Evaluation ---")
    # SpikingCNN ã¯ BaseModel ã‚’ç¶™æ‰¿ã—ã¦ã„ãªã„ãŸã‚ã€SNNCoreã§ãƒ©ãƒƒãƒ—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
    # (æ³¨: snn_core.py ã® SpikingCNN ã¯ BaseModel ã‚’ç¶™æ‰¿ã—ã¦ã„ã‚‹ãŸã‚ã€ãƒ©ãƒƒãƒ—ä¸è¦)
    
    # SNNãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ (SpikingCNN ã¯ BaseModel ã‚’ç¶™æ‰¿ã—ã¦ã„ã‚‹ã¨ä»®å®š)
    snn_accuracy = evaluate_snn(snn_model, device, test_loader, time_steps)
    
    logger.info(f"--- ğŸ“Š Results ---")
    logger.info(f"Converted SNN Accuracy (T={time_steps}): {snn_accuracy:.2f}%")
    logger.info("è¨­è¨ˆæ€æƒ³ (ã‚»ã‚¯ã‚·ãƒ§ãƒ³6.3) ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ¤œè¨¼ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
