# **SNN5 高度化ロードマップ (v10.4): 「Bio/LNN Track」優先とSOTA技術の戦略的融合**

## **I. 基本方針**

Objective.md (v1.1) で定義された核心目標、特に「**④ 非GPU依存**」「**⑤ 非勾配型学習システム**」「**⑥ 修正可能なAI**」の達成を最優先事項とする。

プロジェクトSNN5は、SOTA（State-of-the-Art）レベルのAIフレームワークへと強化される。このため、学習パラダイムを以下の3つの戦略的トラックに分離・定義する。

1. **【本流】生物学的パラダイム (Bio / LNN Track):**  
   * **目的:** Objective.mdの目標④, ⑤, ⑥を達成する、プロジェクトの**最重要トラック**。  
   * **技術:** **Liquid Neural Network (LNN) / Reservoir Computingの原理**と、\*\*局所的な可塑性ルール（STDP, R-STDP, BCM, Hebbian等）\*\*に基づく微分フリー学習則を用いる。  
   * **展開:** ニューロモーフィック・ハードウェア（Intel Loihi 2, SpiNNaker）上での「オンチップ学習」と「継続的適応」を最終目標とする。  
2. **【戦略トラックA】ANN-SNN変換 (SFN Track):**  
   * **目的:** Objective.mdの目標①（高精度 ≥96%）および②（高効率 ≤1/50, 低レイテンシ ≤10ms）を、**静的タスク（画像分類など）において**最短で達成する。  
   * **技術:** SOTAのANN（ResNet, ViT）を訓練後、「Scale-and-Fire Neuron (SFN)」等の最新変換技術（SOTAリサーチ 1.2節）を用い、T=1（単一タイムステップ）の超低レイテンシSNNを生成する。  
   * **展開:** GPU（推論用）またはニューロモーフィック・ハードウェア（推論用）。  
3. **【戦略トラックB】代理勾配 (SG Track):**  
   * **目的:** SNN固有の「時間的学習能力」を最大化し、\*\*動的タスク（時系列、DVS、音声）\*\*におけるSOTA精度を目指す。また、Bio Trackの学習則（R-STDP）のハイパーパラメータをGPU上で事前最適化する「メタ学習」（SOTAリサーチ 3.3節）の基盤としても機能する。  
   * **技術:** 代理勾配（Surrogate Gradient: SG）法によるエンドツーエンドの直接訓練。  
   * **展開:** GPU（訓練・推論）またはニューロモーフィック・ハードウェア（推論用）。

## **II. 実装ロードマップ (v10.4)**

### **フェーズ1: 高精度アーキテクチャの分岐実装 (All Tracks)**

ANN SOTAに匹敵する精度基盤を、各トラックの特性に合わせて構築する。

| ID | タスク | 概要 | 担当トラック | SOTA技術 | 参照(強化案) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| **P1.1** | **深層残差SNNの実装** | 勾配消失を防ぐ残差接続を実装する。 | **SG Track** | **SEW-ResNet** 9 | 2.1 | 計画中 |
| **P1.2** | **イベント駆動型Transformer** | SNNネイティブの純粋なイベント駆動型Transformerを実装する。 | **SG Track** | **Spikingformer** 9 | 5.1 | 計画中 |
| **P1.3** | **ハイブリッドTransformer** | ANNのAttentionとSNNのFFNを組み合わせたハイブリッドTransformerを実装する。 | **SG Track** | **HsVT** 53 | 5.2 | 計画中 |
| **P1.4** | **時空間アテンション** | SNN固有の時間情報を活用するため、スパイクベースの時空間アテンション・モジュールを実装する。 | **SG Track** | **DTA-SNN** 10, **STAA-SNN** 11 | 2.2 | 計画中 |
| **P1.5** | **SFN変換パイプラインの構築** | 高性能ANN (ViT等) を訓練し、T=1のSNNに変換するパイプラインを構築する。 | **SFN Track** | **SFN** 26, **SFormer** 27 | SOTAリサーチ 1.2節 | 計画中 |

### **フェーズ2: ニューロン・ダイナミクスと堅牢性の強化 (All Tracks)**

ニューロンモデルとコーディング方式を高度化し、Objective.mdの目標③（再現性・ノイズ耐性）を達成する。

| ID | タスク | 概要 | SOTA技術 | 参照(強化案) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P2.1** | **学習可能な動的ニューロン (EL)** | P2.1 (PLIF) / P2.2 (GLIF) を拡張し、膜時定数($\\tau$)が入力依存で動的に進化する「Evolutionary Leak (EL)」機構を実装する。 | **FEEL-SNN (EL)** 47 | 3.1, SOTAリサーチ 2.2節 | 計画中 |
| **P2.2** | **堅牢な周波数エンコーディング (FE)** | P2.3 (TTFS移行) に加え、ノイズ周波数帯をフィルタリングする「Frequency Encoding (FE)」を実装する。 | **FEEL-SNN (FE)** 47 | 3.2, SOTAリサーチ 2.2節 | 計画中 |
| **P2.3** | **時間コーディングの最適化** | レートコーディングから、高速・高効率なTTFS（Time-to-First-Spike）コーディングへ移行する。 | **TTFS** 30, 84 | 3.2 | 計画中 |

### **フェーズ3: SOTAモデルのHPOチューニング (All Tracks)**

GPUの計算能力を活用し、各トラックの性能を最大化する。

| ID | タスク | 概要 | SOTA技術 | 関連(SNN5) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P3.1** | **戦略的HPO (SG/Bio Track)** | **(SG Track)** P1で実装したモデル（Spikingformer等）の精度を最大化する。 **(Bio Track)** 3因子学習ルール（R-STDP）等のハイパーパラメータ（時定数、学習率）をGPU上で事前最適化する（メタ学習）。 | **Optuna**, **メタ学習** 41 | run\_hpo.py | 計画中 |

### **フェーズ4: 省エネ化（エネルギー効率）の徹底追求 (SG / SFN Tracks)**

高精度トラック（SG/SFN）のモデルに対し、Objective.mdの目標②（効率 ≤1/50）を達成するための技術を適用する。

| ID | タスク | 概要 | SOTA技術 | 参照(強化案) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P4.1** | **スパース性正則化** | 損失関数にスパイク率ペナルティを導入し、スパースな発火（省エネ）を強制する。 | スパース性正則化 12, 13 | 4.2 | 計画中 |
| **P4.2** | **量子化アウェア学習 (QAT)** | 2ビットや4ビットなどの低ビット精度で学習・推論を行い、メモリと演算コストを劇的に削減する。 | **QUEST** 14 | 4.3 | 計画中 |
| **P4.3** | **ワンショット・プルーニング** | ヘッセ行列（SBC/OBC）に基づき再学習不要でネットワークを剪定し、開発サイクルを高速化する。 | **SBC** 15 | 4.4 | 計画中 |

### **フェーズ5: ニューロモーフィック・デプロイメント (All Tracks)**

Objective.mdの目標④（非GPU依存）を達成するための最終的な実行環境への展開。

| ID | タスク | 概要 | SOTA技術 | 参照(強化案) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P5.1** | **動的推論 (SNN Cutoff)** | 推論の途中で確信度を監視し、早期終了させレイテンシを動的に削減する。 | **SNN Cutoff** 16, 58 | 6.1 | 計画中 |
| **P5.2** | **HW協調設計 (Lava)** | **(SG/SFN Track)** P1/P4の最適化済モデルを推論用にLoihi 2へ移植する。 **(Bio Track)** P8で実装したR-STDP学習則をLoihi 2に移植し、「**オンチップ学習**」を実行する。 | **Lava Framework** 61, 39 | 6.2, SOTAリサーチ 3.3節 | 計画中 |
| **P5.3** | **HW協調設計 (SpiNNaker)** | P1/P4/P8のモデルをSpiNNaker向けのsPyNNakerフレームワークへ移植する。 | **sPyNNaker** 69 | 6.2 | 計画中 |

### **フェーズ6: 統合的効率化検証 (SG / SFN Tracks)**

目標①（高精度）と目標②（高効率）の両立を最終検証する。

| ID | タスク | 概要 | SOTA技術 | 関連(SNN5) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P6.1** | **統合効率化モデルの構築** | P3でチューニングしたSG/SFNモデルに対し、P2.3 (TTFS), P4 (省エネ化), P5.1 (SNN Cutoff) の技術を**すべて適用**した最終モデルを構築する。 | 複合技術 | pruning.py, quantization.py, deployment.py | 計画中 |
| **P6.2** | **最終効率ベンチマーク** | P6.1で構築した「最終モデル」を P7.3 (SNNBench) で評価し、精度と消費電力（SynOps）を測定。ANN比1/50の目標達成度を最終判定する。 | **SNNBench** 79 | run\_benchmark\_suite.py | 計画中 |

### **フェーズ7: ベンチマークと基盤整備 (All Tracks)**

開発基盤をSOTAフレームワークに準拠させ、客観的な評価体制を構築する。

| ID | タスク | 概要 | SOTA技術 | 参照(強化案) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P7.1 (優先)** | **開発基盤の移行 (SpikingJelly)** | P5.2 (Lava展開) への最も実践的なパス (lava\_exchange) を持つ **SpikingJelly** フレームワークを、全トラックの標準開発基盤として**最優先で**採用・移行する。 | **SpikingJelly** 24, 67 | 7.1, SOTAリサーチ 3.2節 | **最優先** |
| **P7.2** | **ニューロモーフィック・データセット対応** | SG Trackの評価のため、CIFAR10-DVS, SHD, N-Caltech101 等のイベントベースデータセットを標準でサポートする。 | DVS/SHD Datasets 74 | 7.1 | 計画中 |
| **P7.3** | **統合ベンチマークの確立** | 評価指標として「精度」「SynOps（消費電力）」「スパイクレート」に加え、「**時間反転テスト**」（SOTAリサーチ 1.1節）を追加し、真の時間的学習能力を検証する。 | **SNNBench** 79 | 7.1, SOTAリサーチ 1.1節 | 計画中 |

### **フェーズ8: 生物学的パラダイムの強化 (Bio / LNN Track \- 本流)**

Objective.mdの目標③（再現性）、④（非GPU）、⑤（非BP）を達成するための**プロジェクト本流**。

| ID | タスク | 概要 | 参照コード | 関連(SNN5) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P8.1 (強化)** | **LNN/リザバー・コンピューティング実装** | LNN\_RSNN\_design\_spec.md に基づき、(STDP訓練リザバー \+ 線形リードアウト) というLSM/LNNベースラインを PyTorch で実装し、SpikingSSM 等の性能と比較する。 | prototype\_rsnn.py | spiking\_ssm.py | **計画中** |
| **P8.2** | **E/Iバランスの実装** | デールの法則（E/I分離）を snn\_research/bio\_models/simple\_network.py に正式に実装し、学習の安定性を評価する。 | rsnn\_experiments\_fixed.py | simple\_network.py | 計画中 |
| **P8.3** | **恒常性（適応的閾値）の実装** | LNN\_RSNN\_design\_spec.md (5.ダイナミクス制御) に基づき、適応的発火閾値による恒常性維持メカニズムを BioSNN に実装し、BCMLearningRule と比較検証する。 | rsnn\_experiments\_fixed.py | bcm\_rule.py | 計画中 |
| **P8.4** | **Bio Track 再現性の安定化** | 目標③(再現性95%)のため、Bio Trackの確率的挙動を分析し、シード値固定や決定論的STDPの実装検討により学習の再現性を確保する計画を策定する。 | prototype\_rsnn.py | learning\_rules/stdp.py | 計画中 |
| **P8.5** | **3因子学習則のLoihi 2実装** | SOTAリサーチ 1.3節に基づき、R-STDP学習則をLavaフレームワークで実装し、P5.2と連携して「**オンチップ学習**」を実現する。 | (SOTAリサーチ 39\) | reward\_modulated\_stdp.py | 計画中 |
| **P8.6 (新規)** | **減衰付きHebbianルールの実装** | LNN\_RSNN\_design\_spec.md (4.1 局所更新ルール) で提案されたシンプルな減衰付きヘブ則（Δw \= η (s\_i \* s\_j \- β\*w)）を実装し、ProbabilisticHebbian と性能・安定性を比較検証する。 | (LNN\_RSNN\_design\_spec.md) | probabilistic\_hebbian.py | **計画中** |

