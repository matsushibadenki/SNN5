# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: run_compiler_test.py
# (æ›´æ–°)
#
# Title: ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ¢ãƒ¼ãƒ•ã‚£ãƒƒã‚¯ãƒ»ã‚³ãƒ³ãƒ‘ã‚¤ãƒ© ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#
# Description:
# - ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã€Œãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ¢ãƒ¼ãƒ•ã‚£ãƒƒã‚¯ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¸ã®æœ€é©åŒ–ã€ã§å®Ÿè£…ã—ãŸ
#   NeuromorphicCompilerã®å‹•ä½œã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
# - ãƒ€ãƒŸãƒ¼ã®BioSNNãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€ãã‚Œã‚’ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«ã«
#   ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
#
# æ”¹å–„ç‚¹(v2):
# - ROADMAPãƒ•ã‚§ãƒ¼ã‚º6ã«åŸºã¥ãã€ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¾Œã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ€§èƒ½ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹å‡¦ç†ã‚’è¿½åŠ ã€‚
# æ”¹å–„ç‚¹(v3): ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã«å­¦ç¿’å‰‡ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹æ¤œè¨¼ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ã€‚
# æ”¹å–„ç‚¹(snn_4_ann_parity_plan):
# - å­¦ç¿’å‰‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼ã‚’ã‚ˆã‚Šå³å¯†åŒ–ã€‚
# - å¤ã„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‰Šé™¤ã—ã€ã“ã¡ã‚‰ã«æ©Ÿèƒ½ã‚’çµ±åˆã€‚
# - ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é©ç”¨ã—ã€æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹æ©Ÿèƒ½ã‚’è¿½åŠ ã€‚
# ä¿®æ­£: CausalTraceCreditAssignment -> CausalTraceCreditAssignmentEnhanced
# ä¿®æ­£: CausalTraceCreditAssignmentEnhancedV2 ã«å¯¾å¿œ
#
# ä¿®æ­£ (v7):
# - mypy [attr-defined] ã‚¨ãƒ©ãƒ¼ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€apply_magnitude_pruning ã‚’
#   apply_sbc_pruning ã«å¤‰æ›´ã—ã€ãƒ€ãƒŸãƒ¼ã®å¼•æ•°ã‚’è¿½åŠ ã€‚
#
# æ”¹å–„ (v8):
# - BioSNN ã«åŠ ãˆã€SNNCore ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ« (SEW-ResNet) ã®
#   ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚ˆã†æ‹¡å¼µã€‚
# - DIã‚³ãƒ³ãƒ†ãƒŠ (TrainingContainer) ã‚’ä½¿ç”¨ã—ã¦ SNNCore ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã€‚
#
# ä¿®æ­£ (v9):
# - mypy [misc], [union-attr] ã‚¨ãƒ©ãƒ¼ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€
#   pruned_model ã¨ snn_core_model ã‚’ cast ã™ã‚‹ã‚ˆã†ä¿®æ­£ã€‚
#
# ä¿®æ­£ (v10):
# - mypy [call-arg] ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã€‚
# - BioSNN ã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿å¼•æ•°ã‚’ `learning_rule` ã‹ã‚‰ `synaptic_rule` ã«å¤‰æ›´ã€‚

import sys
from pathlib import Path
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import yaml
import copy
# --- â–¼ ä¿®æ­£: å¿…è¦ãªå‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ  â–¼ ---
from typing import Dict, Any, cast
from omegaconf import OmegaConf
# --- â–² ä¿®æ­£ â–² ---

sys.path.append(str(Path(__file__).resolve().parent))

from snn_research.bio_models.simple_network import BioSNN
from snn_research.learning_rules.causal_trace import CausalTraceCreditAssignmentEnhancedV2
from snn_research.hardware.compiler import NeuromorphicCompiler
from snn_research.training.pruning import apply_sbc_pruning
# --- â–¼ ä¿®æ­£: SNNCoreãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã®ãŸã‚ã« DIã‚³ãƒ³ãƒ†ãƒŠã¨SNNCoreã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â–¼ ---
from app.containers import TrainingContainer
from snn_research.core.snn_core import SNNCore
# --- â–² ä¿®æ­£ â–² ---


def test_biosnn_compilation(compiler: NeuromorphicCompiler, output_dir: str) -> None:
    """BioSNNãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã¨ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚"""
    print("\n--- 1. BioSNNãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")
    
    learning_rate = 0.005
    learning_rule = CausalTraceCreditAssignmentEnhancedV2(
        learning_rate=learning_rate, a_plus=1.0, a_minus=1.0,
        tau_trace=20.0, tau_eligibility=50.0
    )
    # --- â–¼ ä¿®æ­£(v10): [call-arg] learning_rule -> synaptic_rule â–¼ ---
    model = BioSNN(
        layer_sizes=[10, 20, 5],
        neuron_params={'tau_mem': 10.0, 'v_threshold': 1.0, 'v_reset': 0.0, 'v_rest': 0.0},
        synaptic_rule=learning_rule, # learning_rule ã‚’ synaptic_rule ã«å¤‰æ›´
        homeostatic_rule=None,      # homeostatic_rule ã‚’ None ã§æŒ‡å®š
        sparsification_config={"enabled": True, "contribution_threshold": 0.01} # ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ã‚‚æœ‰åŠ¹åŒ–
    )
    # --- â–² ä¿®æ­£(v10) â–² ---
    print("âœ… ãƒ€ãƒŸãƒ¼ã®BioSNNãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚")

    # --- â–¼ ä¿®æ­£: mypy [misc], [union-attr] ã‚¨ãƒ©ãƒ¼è§£æ¶ˆ (L87) â–¼ ---
    # apply_sbc_pruning ã¯ nn.Module ã‚’è¿”ã™ãŸã‚ã€BioSNN ã«ã‚­ãƒ£ã‚¹ãƒˆã™ã‚‹
    pruned_model_uncast: nn.Module = apply_sbc_pruning(
        copy.deepcopy(model), 
        amount=0.3,
        dataloader_stub=DataLoader(TensorDataset(torch.randn(10, 10), torch.randn(10, 5)), batch_size=2),
        loss_fn_stub=nn.MSELoss()
    )
    pruned_model: BioSNN = cast(BioSNN, pruned_model_uncast)
    
    original_connections = sum(torch.sum(w > 0).item() for w in model.weights)
    pruned_connections = sum(torch.sum(w > 0).item() for w in pruned_model.weights)
    # --- â–² ä¿®æ­£ â–² ---
    
    print(f"ğŸ”ª ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã—ãŸ: {original_connections} -> {pruned_connections} connections")
    assert pruned_connections < original_connections

    output_path = os.path.join(output_dir, "compiled_biosnn_pruned_config.yaml")
    compiler.compile(pruned_model, output_path)

    if os.path.exists(output_path):
        print(f"\nâœ… BioSNNã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æˆåŠŸ: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒ '{output_path}' ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        with open(output_path, 'r') as f:
            config = yaml.safe_load(f)
        assert "learning_rule_config" in config
        lr_config = config["learning_rule_config"]
        assert lr_config["rule_name"] == "CausalTraceCreditAssignmentEnhancedV2", "å­¦ç¿’å‰‡ã®åå‰ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚"
        assert "parameters" in lr_config
        params = lr_config["parameters"]
        assert "learning_rate" in params and abs(params["learning_rate"] - learning_rate) < 1e-6
        print("  - æ¤œè¨¼: å­¦ç¿’å‰‡ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«çµæœã¯æ­£å¸¸ã§ã™ã€‚")
        compiled_connections = sum(layer['num_connections'] for layer in config['synaptic_connectivity'])
        assert compiled_connections == pruned_connections
        print(f"  - æ¤œè¨¼: ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°çµæœãŒã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«æ­£ã—ãåæ˜ ã•ã‚Œã¾ã—ãŸ ({compiled_connections} connections)ã€‚")

        simulation_report = compiler.simulate_on_hardware(
            compiled_config_path=output_path,
            total_spikes=15000,
            time_steps=100
        )
        print("\n--- ğŸ“Š BioSNN ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ ---")
        for key, value in simulation_report.items(): print(f"  - {key}: {value:.4e}")
        print("--------------------------------------------------")
    else:
        print(f"\nâŒ BioSNNãƒ†ã‚¹ãƒˆå¤±æ•—: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        raise AssertionError("BioSNNã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—")

def test_snncore_compilation(compiler: NeuromorphicCompiler, output_dir: str) -> None:
    """SNNCore (SEW-ResNet) ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚"""
    print("\n--- 2. SNNCore (SEW-ResNet) ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")

    try:
        container = TrainingContainer()
        container.config.from_yaml("configs/base_config.yaml")
        container.config.from_yaml("configs/cifar10_spikingcnn_config.yaml")
        container.config.model.architecture_type.from_value("sew_resnet")
        
        # --- â–¼ ä¿®æ­£: mypy [union-attr] ã‚¨ãƒ©ãƒ¼è§£æ¶ˆ (L137) â–¼ ---
        # container.snn_model() ãŒ nn.Module ã‚’è¿”ã™å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€SNNCore ã«ã‚­ãƒ£ã‚¹ãƒˆã™ã‚‹
        snn_core_model_uncast: nn.Module = container.snn_model(vocab_size=10)
        snn_core_model: SNNCore = cast(SNNCore, snn_core_model_uncast)
        # --- â–² ä¿®æ­£ â–² ---
        
        snn_core_model.eval()
        print(f"âœ… ãƒ€ãƒŸãƒ¼ã®SNNCoreãƒ¢ãƒ‡ãƒ« ({snn_core_model.config.architecture_type}) ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        print(f"âŒ SNNCoreãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        print("   SEW-ResNetã®å®Ÿè£… (snn_research/architectures/sew_resnet.py) ãŒå¿…è¦ã§ã™ã€‚")
        return

    output_path = os.path.join(output_dir, "compiled_snncore_sew_resnet_config.yaml")
    compiler.compile(snn_core_model, output_path)
    
    if os.path.exists(output_path):
        print(f"\nâœ… SNNCoreã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æˆåŠŸ: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒ '{output_path}' ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        with open(output_path, 'r') as f:
            config: Dict[str, Any] = yaml.safe_load(f)
            
        assert "network_summary" in config
        summary = config["network_summary"]
        assert summary["total_neurons"] > 0
        assert summary["total_connections"] > 0
        print(f"  - æ¤œè¨¼: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¦‚è¦: Neurons={summary['total_neurons']}, Connections={summary['total_connections']}")
        
        assert "learning_rule_config" in config
        assert config["learning_rule_config"]["rule_name"] == "None"
        print("  - æ¤œè¨¼: å­¦ç¿’å‰‡ (None) ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«çµæœã¯æ­£å¸¸ã§ã™ã€‚")

        estimated_spikes = 500000
        time_steps = container.config.model.time_steps()

        simulation_report = compiler.simulate_on_hardware(
            compiled_config_path=output_path,
            total_spikes=estimated_spikes,
            time_steps=time_steps
        )
        print("\n--- ğŸ“Š SNNCore ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ ---")
        for key, value in simulation_report.items(): print(f"  - {key}: {value:.4e}")
        print("---------------------------------------------------")
    else:
        print(f"\nâŒ SNNCoreãƒ†ã‚¹ãƒˆå¤±æ•—: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        raise AssertionError("SNNCoreã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—")

def main():
    """
    NeuromorphicCompilerã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    """
    print("--- ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ¢ãƒ¼ãƒ•ã‚£ãƒƒã‚¯ãƒ»ã‚³ãƒ³ãƒ‘ã‚¤ãƒ© çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹ ---")

    compiler = NeuromorphicCompiler(hardware_profile_name="default")
    output_dir = "runs/compiler_tests"
    os.makedirs(output_dir, exist_ok=True)

    # ãƒ†ã‚¹ãƒˆ1: BioSNN (ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚° + å­¦ç¿’å‰‡)
    try:
        test_biosnn_compilation(compiler, output_dir)
    except Exception as e:
        print(f"âŒ BioSNNã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # ãƒ†ã‚¹ãƒˆ2: SNNCore (SEW-ResNet)
    try:
        test_snncore_compilation(compiler, output_dir)
    except Exception as e:
        print(f"âŒ SNNCoreã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


    print("\n--- ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ¢ãƒ¼ãƒ•ã‚£ãƒƒã‚¯ãƒ»ã‚³ãƒ³ãƒ‘ã‚¤ãƒ© çµ±åˆãƒ†ã‚¹ãƒˆçµ‚äº† ---")

if __name__ == "__main__":
    main()