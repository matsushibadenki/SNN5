# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/run_project_health_check.py
# (æ–°è¦ä½œæˆ)
#
# Title: SNNãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ (Health Check)
#
# Description:
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ä¸»è¦ãªæ©Ÿèƒ½ï¼ˆä»£ç†å‹¾é…å­¦ç¿’ã€ç”Ÿç‰©å­¦çš„å­¦ç¿’ã€
# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆï¼‰ãŒã€
# æœ€å°é™ã®è¨­å®šã§ã‚¨ãƒ©ãƒ¼ãªãå‹•ä½œã™ã‚‹ã‹ã‚’è¿…é€Ÿã«æ¤œè¨¼ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
# æœ¬æ ¼çš„ãªãƒ†ã‚¹ãƒˆã®å‰ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’æƒ³å®šã€‚
#
# mypy --strict æº–æ‹ ã€‚
#
# ä¿®æ­£ (v2):
# - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒã‚§ãƒƒã‚¯ (check2) ãŒ --eval_only ã§å¤±æ•—ã—ã¦ã„ãŸå•é¡Œã‚’ä¿®æ­£ã€‚
# - --eval_only é–¢é€£ã®å¼•æ•°ã‚’å‰Šé™¤ã—ã€--epochs 1 --batch_size 4 ã§
#   å®Ÿéš›ã«æœ€å°é™ã®è¨“ç·´ãƒ»è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ã€‚

import subprocess
import sys
import logging
from typing import List, Tuple, Optional
from pathlib import Path

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("HealthCheck")

# Pythonå®Ÿè¡Œå¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
PYTHON_EXEC = sys.executable

def _run_check(command: List[str], check_name: str) -> bool:
    """ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã—ã€æˆåŠŸ/å¤±æ•—ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ã™ã‚‹ãƒ©ãƒƒãƒ‘ãƒ¼"""
    logger.info(f"\n--- ğŸƒ å®Ÿè¡Œä¸­: {check_name} ---")
    logger.info(f"ã‚³ãƒãƒ³ãƒ‰: {' '.join(command)}")
    
    try:
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å‡ºåŠ›
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            encoding='utf-8',
            bufsize=1
        )
        
        if process.stdout:
            for line in iter(process.stdout.readline, ''):
                # ãƒ­ã‚°ãŒé•·ããªã‚Šã™ããªã„ã‚ˆã†ã€ç°¡æ˜“çš„ã«è¡¨ç¤º
                if "Epoch" in line or "Result" in line or "INFO" in line or "Error" in line or "fail" in line.lower() or "warning" in line.lower():
                    logger.info(f"  [{check_name}] {line.strip()}")
                else:
                    # tqdmã®é€²æ—ãªã©ã¯çœç•¥
                    pass
        
        process.wait()
        
        if process.returncode == 0:
            logger.info(f"--- âœ… æˆåŠŸ: {check_name} ---")
            return True
        else:
            logger.error(f"--- âŒ å¤±æ•—: {check_name} (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {process.returncode}) ---")
            return False
            
    except FileNotFoundError:
        logger.error(f"--- âŒ å¤±æ•—: {check_name} (ã‚³ãƒãƒ³ãƒ‰ '{command[0]}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“) ---")
        return False
    except Exception as e:
        logger.error(f"--- âŒ å¤±æ•—: {check_name} (äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}) ---")
        return False

def main() -> None:
    logger.info("="*30 + " ğŸ©º SNNãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå¥å…¨æ€§ãƒã‚§ãƒƒã‚¯é–‹å§‹ " + "="*30)
    
    checks: List[Tuple[bool, str]] = []
    
    # 1. ç°¡æ˜“å­¦ç¿’ãƒ†ã‚¹ãƒˆ (Gradient-based)
    # configs/smoke_test_config.yaml (epoch=1, batch=2) ã‚’ä½¿ç”¨
    check1_cmd = [
        PYTHON_EXEC, "train.py",
        "--config", "configs/smoke_test_config.yaml",
        "--model_config", "configs/models/micro.yaml",
        "--paradigm", "gradient_based"
    ]
    checks.append((_run_check(check1_cmd, "1. ä»£ç†å‹¾é…å­¦ç¿’ (gradient_based)"), "ä»£ç†å‹¾é…å­¦ç¿’"))

    # 2. ç°¡æ˜“ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ (ANN vs SNN)
    # --- â–¼ ä¿®æ­£(v2): --eval_only ã‚’å‰Šé™¤ã—ã€å®Ÿéš›ã«æœ€å°é™ã®è¨“ç·´ã‚’å®Ÿè¡Œ â–¼ ---
    check2_cmd = [
        PYTHON_EXEC, "scripts/run_benchmark_suite.py",
        "--experiment", "cifar10_comparison",
        "--epochs", "1",
        "--batch_size", "4", # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ã
        # "--eval_only", # å‰Šé™¤
        # "--model_type", "SNN", # å‰Šé™¤ (ANNã¨SNNã®ä¸¡æ–¹ã‚’å®Ÿè¡Œ)
        # "--model_path", "runs/dummy_model_for_check.pth", # å‰Šé™¤
        "--model_config", "configs/cifar10_spikingcnn_config.yaml"
    ]
    checks.append((_run_check(check2_cmd, "2. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ (Train+Eval)"), "ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"))
    # --- â–² ä¿®æ­£(v2) â–² ---


    # 3. ç°¡æ˜“ãƒ»ç”Ÿç‰©å­¦çš„å­¦ç¿’ãƒ†ã‚¹ãƒˆ (Bio-RL)
    # 5ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ã¿
    check3_cmd = [
        PYTHON_EXEC, "run_rl_agent.py",
        "--episodes", "5",
        "--output_dir", "runs/health_check_rl"
    ]
    checks.append((_run_check(check3_cmd, "3. ç”Ÿç‰©å­¦çš„å­¦ç¿’ (Bio-RL)"), "ç”Ÿç‰©å­¦çš„å­¦ç¿’"))

    # 4. ç°¡æ˜“ãƒ»èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ†ã‚¹ãƒˆ
    check4_cmd = [
        PYTHON_EXEC, "run_brain_simulation.py",
        "--prompt", "Health check prompt",
        "--model_config", "configs/models/micro.yaml"
    ]
    checks.append((_run_check(check4_cmd, "4. èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (ArtificialBrain)"), "èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£"))

    # 5. ç°¡æ˜“ãƒ»åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆ
    check5_cmd = [
        PYTHON_EXEC, "scripts/report_sparsity_and_T.py",
        "--model_config", "configs/models/micro.yaml",
        "--data_path", "data/smoke_test_data.jsonl"
    ]
    checks.append((_run_check(check5_cmd, "5. åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆ (Sparsity & T)"), "åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆ"))
    
    # --- æœ€çµ‚çµæœ ---
    logger.info("\n" + "="*30 + " ğŸ©º å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯å®Œäº† " + "="*30)
    total = len(checks)
    success = sum(1 for c in checks if c[0])
    
    logger.info(f"çµæœ: {success} / {total} ã®ä¸»è¦æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã—ã¾ã—ãŸã€‚")
    for status, name in checks:
        logger.info(f"  - [{ 'âœ… æˆåŠŸ' if status else 'âŒ å¤±æ•—' }] {name}")
        
    if success < total:
        logger.error("ä¸€éƒ¨ã®æ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ä¸Šè¨˜ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    else:
        logger.info("å…¨ã¦ã®ä¸»è¦æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
