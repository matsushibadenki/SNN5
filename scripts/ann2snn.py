# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/ann2snn.py
# (æ”¹ä¿®)
#
# Title: ANN-SNN å¤‰æ› å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#
# Description:
# doc/SNNé–‹ç™ºï¼šåŸºæœ¬è¨­è¨ˆæ€æƒ³.md (ã‚»ã‚¯ã‚·ãƒ§ãƒ³6.3) ã«åŸºã¥ãã€
# 1. ANNãƒ¢ãƒ‡ãƒ« (SimpleCNN) ã‚’CIFAR-10ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ã€
# 2. è¨“ç·´æ¸ˆã¿ANNãƒ¢ãƒ‡ãƒ«ã‚’ SNNãƒ¢ãƒ‡ãƒ« (SpikingCNN) ã«å¤‰æ›ã—ã€
# 3. å¤‰æ›å¾Œã®SNNãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è©•ä¾¡ã™ã‚‹ã€
# ã¨ã„ã†ä¸€é€£ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
#
# æ”¹å–„ (v2):
# - mypy --strict æº–æ‹ ã®ãŸã‚ã®å‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ ã€‚
# - printæ–‡ã‚’ logging ã«ç½®ãæ›ãˆã€‚
#
# ä¿®æ­£ (v3):
# - mypy [attr-defined] (ANNToSNNConverter -> AnnToSnnConverter) ã‚’ä¿®æ­£ã€‚
# - mypy [assignment] (int = float) ã‚’ä¿®æ­£ã€‚
#
# ä¿®æ­£ (v4):
# - mypy [call-arg] [attr-defined] ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã€‚
# - AnnToSnnConverter ã®æ–°ã—ã„API (v3) ã«åˆã‚ã›ã¦å‘¼ã³å‡ºã—æ–¹æ³•ã‚’ä¿®æ­£ã€‚
#
# ä¿®æ­£ (v5):
# - AnnToSnnConverter ã® API (v3) ã¸ã®é©åˆã‚’å†ç¢ºèªã€‚
# - AnnToSnnConverter ã¯ snn_model ã¨ model_config ã‚’ __init__ ã§è¦æ±‚ã™ã‚‹ã€‚
# - å¤‰æ›å®Ÿè¡Œã¯ convert_cnn_weights ãƒ¡ã‚½ãƒƒãƒ‰ã§è¡Œã†ã€‚

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms # type: ignore[import-untyped]
from torch.utils.data import DataLoader
import sys
from pathlib import Path
import logging 
from typing import Dict, Any, cast, Tuple, List 
import os 

sys.path.append(str(Path(__file__).resolve().parent.parent))

from snn_research.benchmark.ann_baseline import SimpleCNN
# --- â–¼ ä¿®æ­£: ã‚¯ãƒ©ã‚¹åã‚’ AnnToSnnConverter ã«å¤‰æ›´ â–¼ ---
from snn_research.conversion.ann_to_snn_converter import AnnToSnnConverter 
# --- â–² ä¿®æ­£ â–² ---
from snn_research.core.snn_core import SpikingCNN # å¤‰æ›å¾Œã®SNNãƒ¢ãƒ‡ãƒ«
from snn_research.core.neurons import AdaptiveLIFNeuron
from spikingjelly.activation_based import functional as SJ_F # type: ignore[import-untyped]

# --- ãƒ­ã‚¬ãƒ¼è¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def train_ann(
    model: nn.Module, 
    device: torch.device, 
    train_loader: DataLoader, 
    optimizer: optim.Optimizer, 
    epoch: int
) -> None:
    model.train()
    criterion = nn.CrossEntropyLoss()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % 100 == 0:
            logger.info(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ' # type: ignore[arg-type]
                        f'({100. * batch_idx / len(train_loader):.0f}%)]\tLoss: {loss.item():.6f}')

def evaluate_snn(
    model: nn.Module, 
    device: torch.device, 
    test_loader: DataLoader, 
    time_steps: int
) -> float:
    model.eval()
    # --- â–¼ ä¿®æ­£: [assignment] ã‚¨ãƒ©ãƒ¼ (int = float) ã‚’å›é¿ â–¼ ---
    correct: float = 0.0
    # --- â–² ä¿®æ­£ â–² ---
    total: int = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            
            # SNNè©•ä¾¡ (SpikingCNNã¯å†…éƒ¨ã§Tã‚¹ãƒ†ãƒƒãƒ—ãƒ«ãƒ¼ãƒ—)
            SJ_F.reset_net(model)
            # SpikingCNNã¯ (logits, avg_spikes, mem) ã‚’è¿”ã™
            outputs, _, _ = model(input_images=data) # type: ignore[operator]
            
            # æœ€çµ‚çš„ãªãƒ­ã‚¸ãƒƒãƒˆ (æ™‚é–“å¹³å‡æ¸ˆã¿)
            final_logits: torch.Tensor = outputs
            
            pred = final_logits.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)

    accuracy = 100. * correct / total
    return accuracy

def main() -> None:
    # --- 1. æº–å‚™ ---
    use_cuda: bool = torch.cuda.is_available()
    device: torch.device = torch.device("cuda" if use_cuda else "cpu")
    logger.info(f"Using device: {device}")

    # CIFAR-10 ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    
    train_loader: DataLoader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
    test_loader: DataLoader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)

    # --- 2. ANNãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨è¨“ç·´ ---
    logger.info("--- 1. ANN Training ---")
    ann_model: SimpleCNN = SimpleCNN(num_classes=10).to(device)
    optimizer: optim.Optimizer = optim.Adam(ann_model.parameters(), lr=0.001)
    
    ann_epochs: int = 3 # ç°¡æ˜“çš„ãªè¨“ç·´
    for epoch in range(1, ann_epochs + 1):
        train_ann(ann_model, device, train_loader, optimizer, epoch)
    
    ann_model.eval()
    logger.info("âœ… ANN training complete.")

    # --- 3. ANN-SNN å¤‰æ› ---
    logger.info("--- 2. ANN-to-SNN Conversion ---")
    
    # å¤‰æ›å¾Œã®SNNãƒ¢ãƒ‡ãƒ«ï¼ˆSpikingCNNï¼‰ã®è¨­å®š
    time_steps: int = 16
    neuron_config: Dict[str, Any] = {
        'type': 'lif',
        'tau_mem': 10.0,
        'base_threshold': 1.0 # é–¾å€¤ã¯å¤‰æ›æ™‚ã«èª¿æ•´ã•ã‚Œã‚‹
    }
    
    # å¤‰æ›å¾Œã®SNNãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ– (é‡ã¿ã¯ãƒ€ãƒŸãƒ¼)
    # vocab_size=10 (num_classes)
    snn_model_skel: SpikingCNN = SpikingCNN(vocab_size=10, time_steps=time_steps, neuron_config=neuron_config)
    
    # å¤‰æ›å™¨ã®åˆæœŸåŒ–ã¨å®Ÿè¡Œ
    # ANNãƒ¢ãƒ‡ãƒ«ã®ReLUã‚’SNNã®LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«ãƒãƒƒãƒ”ãƒ³ã‚°
    # --- â–¼ ä¿®æ­£: AnnToSnnConverter ã®æ–°ã—ã„API (v3) ã«åˆã‚ã›ã¦ä¿®æ­£ â–¼ ---
    snn_config_dict: Dict[str, Any] = {
        "time_steps": time_steps,
        "neuron": neuron_config
    }
    
    converter = AnnToSnnConverter(
        snn_model=snn_model_skel, 
        model_config=snn_config_dict
    )
    
    output_dir = "runs/ann2snn_tests"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "converted_snn_model.pth")
    
    # å¤‰æ›ã‚’å®Ÿè¡Œ (å†…éƒ¨ã§æ­£è¦åŒ–ã€é–¾å€¤èª¿æ•´ã€é‡ã¿ã‚³ãƒ”ãƒ¼ãŒè¡Œã‚ã‚Œã‚‹)
    converter.convert_cnn_weights(
        ann_model=ann_model,
        output_path=output_path,
        calibration_loader=train_loader # é–¾å€¤èª¿æ•´ç”¨ã«ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æ¸¡ã™
    )
    
    # å¤‰æ›å™¨ãŒä¿æŒã—ã¦ã„ã‚‹SNNãƒ¢ãƒ‡ãƒ«ï¼ˆé‡ã¿ã‚³ãƒ”ãƒ¼æ¸ˆã¿ï¼‰ã‚’å–å¾—
    snn_model: nn.Module = converter.snn_model
    # --- â–² ä¿®æ­£ â–² ---
    
    snn_model = snn_model.to(device)
    logger.info("âœ… ANN-SNN conversion complete.")

    # --- 4. SNNãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ ---
    logger.info("--- 3. SNN Evaluation ---")
    
    snn_accuracy = evaluate_snn(snn_model, device, test_loader, time_steps)
    
    logger.info(f"--- ğŸ“Š Results ---")
    logger.info(f"Converted SNN Accuracy (T={time_steps}): {snn_accuracy:.2f}%")
    logger.info("è¨­è¨ˆæ€æƒ³ (ã‚»ã‚¯ã‚·ãƒ§ãƒ³6.3) ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ¤œè¨¼ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
