# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/learning_rules/bcm_rule.py
# (æ–°è¦ä½œæˆ)
#
# Title: BCM (Bienenstock-Cooper-Munro) å­¦ç¿’è¦å‰‡
#
# Description:
# doc/ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå¼·åŒ–æ¡ˆã®èª¿æŸ».md (ã‚»ã‚¯ã‚·ãƒ§ãƒ³2.3, å¼•ç”¨[35, 38]) ã«åŸºã¥ãå®Ÿè£…ã€‚
# ãƒ˜ãƒ–å‰‡ï¼ˆSTDPãªã©ï¼‰ã«ã‚ˆã‚‹å­¦ç¿’ã®ä¸å®‰å®šæ€§ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã®ã€
# ç”Ÿç‰©å­¦çš„ã«å¦¥å½“ãªãƒ›ãƒ¡ã‚ªã‚¹ã‚¿ã‚·ã‚¹ï¼ˆæ’å¸¸æ€§ç¶­æŒï¼‰ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€‚
#
# ã‚·ãƒŠãƒ—ã‚¹å¾Œãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®é•·æœŸçš„ãªå¹³å‡æ´»å‹• (avg_post_activity) ã«åŸºã¥ã„ã¦
# å¯å¡‘æ€§ã®é–¾å€¤ (theta) ã‚’å‹•çš„ã«å¤‰æ›´ã—ã€ç™ºç«ç‡ã‚’å®‰å®šã•ã›ã‚‹ã€‚
#
# mypy --strict æº–æ‹ ã€‚

import torch
from typing import Dict, Any, Optional, Tuple, cast
from .base_rule import BioLearningRule

class BCMLearningRule(BioLearningRule):
    """
    BCM (Bienenstock-Cooper-Munro) å­¦ç¿’è¦å‰‡ã€‚
    ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å¹³å‡æ´»å‹•ã«åŸºã¥ã„ã¦å¯å¡‘æ€§é–¾å€¤ã‚’å‹•çš„ã«èª¿æ•´ã—ã€
    ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ’å¸¸æ€§ã‚’ç¶­æŒã™ã‚‹ã€‚
    """
    # (B, N_post) ã®é•·æœŸçš„ãªå¹³å‡æ´»å‹•ã‚’ä¿æŒã™ã‚‹ãƒãƒƒãƒ•ã‚¡
    avg_post_activity: Optional[torch.Tensor]

    def __init__(
        self, 
        learning_rate: float, 
        tau_avg: float, # å¹³å‡æ´»å‹•ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®æ™‚å®šæ•° (ã‚¹ãƒ†ãƒƒãƒ—æ•°)
        target_rate: float, # ç›®æ¨™ã¨ã™ã‚‹å¹³å‡ç™ºç«ç‡ (0-1)
        dt: float = 1.0
    ):
        """
        Args:
            learning_rate (float): å­¦ç¿’ç‡ã€‚
            tau_avg (float): å¹³å‡æ´»å‹•ã®æ™‚å®šæ•°ã€‚å¤§ãã„ã»ã©é•·æœŸçš„ãªå¹³å‡ã«ãªã‚‹ã€‚
            target_rate (float): ç›®æ¨™ã¨ã™ã‚‹å¹³å‡ç™ºç«ç‡ (ä¾‹: 0.1)ã€‚
            dt (float): æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã€‚
        """
        self.learning_rate = learning_rate
        if tau_avg <= 0:
            raise ValueError("tau_avg must be positive")
        self.tau_avg = tau_avg
        if not (0 < target_rate <= 1.0):
             raise ValueError("target_rate must be between 0 and 1.0")
        self.target_rate = target_rate
        self.dt = dt
        
        self.avg_post_activity = None
        
        # æŒ‡æ•°ç§»å‹•å¹³å‡ã®ä¿‚æ•° (alpha = dt / tau)
        self.avg_decay_factor = dt / self.tau_avg

        print(f"ğŸ§  BCM Learning Rule initialized (Target Rate: {target_rate}, Tau Avg: {tau_avg})")

    def _initialize_traces(self, post_shape: int, device: torch.device):
        """å¹³å‡æ´»å‹•ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚"""
        # (N_post,) ã®å½¢çŠ¶ã§åˆæœŸåŒ– (ãƒãƒƒãƒéä¾å­˜ã®é•·æœŸå¹³å‡)
        # BCMã¯ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å˜ä½ã®ãƒ›ãƒ¡ã‚ªã‚¹ã‚¿ã‚·ã‚¹
        self.avg_post_activity = torch.full((post_shape,), self.target_rate, device=device)

    def update(
        self,
        pre_spikes: torch.Tensor,
        post_spikes: torch.Tensor,
        weights: torch.Tensor,
        optional_params: Optional[Dict[str, Any]] = None
    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:
        """
        BCMå‰‡ã«åŸºã¥ã„ã¦é‡ã¿å¤‰åŒ–é‡ã‚’è¨ˆç®—ã™ã‚‹ã€‚
        dw = lr * pre_spikes * phi(post_spikes, avg_post_activity)
        
        Args:
            pre_spikes (torch.Tensor): (N_pre,) ã¾ãŸã¯ (B, N_pre)
            post_spikes (torch.Tensor): (N_post,) ã¾ãŸã¯ (B, N_post)
            weights (torch.Tensor): (N_post, N_pre)
        """
        # ãƒãƒƒãƒå‡¦ç†ã«å¯¾å¿œ (B, N) -> (N,)
        if pre_spikes.dim() > 1:
            pre_spikes_avg = pre_spikes.mean(dim=0)
        else:
            pre_spikes_avg = pre_spikes
            
        if post_spikes.dim() > 1:
            post_spikes_avg = post_spikes.mean(dim=0)
        else:
            post_spikes_avg = post_spikes

        # --- 1. ãƒˆãƒ¬ãƒ¼ã‚¹ã®åˆæœŸåŒ– ---
        if self.avg_post_activity is None or self.avg_post_activity.shape[0] != post_spikes_avg.shape[0]:
            self._initialize_traces(post_spikes_avg.shape[0], pre_spikes.device)
        
        avg_post_activity = cast(torch.Tensor, self.avg_post_activity)

        # --- 2. é•·æœŸå¹³å‡æ´»å‹•ã®æ›´æ–° (æŒ‡æ•°ç§»å‹•å¹³å‡) ---
        # avg[t] = (1 - alpha) * avg[t-1] + alpha * post_spikes
        with torch.no_grad():
            self.avg_post_activity = (
                (1.0 - self.avg_decay_factor) * avg_post_activity + 
                self.avg_decay_factor * post_spikes_avg
            ).detach() # å‹¾é…è¨ˆç®—ã«ã¯ä¸è¦

        # --- 3. BCMé–¾å€¤ (theta) ã®è¨ˆç®— ---
        # theta = E[post]^2 / target_rate (å¼•ç”¨[38]ã«åŸºã¥ãå˜ç´”åŒ–)
        # ã¾ãŸã¯ theta = E[post] (ã‚ˆã‚Šä¸€èˆ¬çš„)
        # ã“ã“ã§ã¯ theta = E[post] (ç¾åœ¨ã®å¹³å‡æ´»å‹•) ã‚’ä½¿ç”¨
        theta = avg_post_activity.clone()
        
        # --- 4. BCMé–¢æ•° (phi) ã®è¨ˆç®— ---
        # phi = post * (post - theta)
        # LTP (post > theta) ã¨ LTD (post < theta) ã‚’å¼•ãèµ·ã“ã™
        
        # (N_post,)
        phi = post_spikes_avg * (post_spikes_avg - theta)
        
        # --- 5. é‡ã¿å¤‰åŒ–é‡ (dw) ã®è¨ˆç®— ---
        # dw = lr * phi * pre_spikes^T
        # (N_post,) * (N_pre,) -> (N_post, N_pre)
        dw = self.learning_rate * torch.outer(phi, pre_spikes_avg)
        
        # å®‰å®šåŒ–ã®ãŸã‚ã®é‡ã¿æ¸›è¡° (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        # dw -= self.learning_rate * 0.001 * weights

        # BCMã¯å±€æ‰€çš„ãªãƒ«ãƒ¼ãƒ«ã§ã‚ã‚Šã€é€†æ–¹å‘ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¿¡å·ã¯ç”Ÿæˆã—ãªã„
        backward_credit = None

        return dw, backward_credit