# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/agent/autonomous_agent.py
# (ä¿®æ­£)
# Title: è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹
# Description: ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠãƒ»å­¦ç¿’ã—ã€æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºæœ¬æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
#              Webæ¤œç´¢ã€è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã€ã‚¹ãƒ‘ã‚¤ã‚¯é€šä¿¡æ©Ÿèƒ½ãªã©ã‚’çµ±åˆã—ã¾ã™ã€‚
# å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€TYPE_CHECKINGã‚’ä½¿ç”¨ã—ã¦
# HierarchicalPlannerã®å‹ãƒ’ãƒ³ãƒˆã‚’è§£æ±ºã™ã‚‹ã€‚
# ä¿®æ­£(v2): çŸ¥è­˜è’¸ç•™ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹éš›ã«ã€
#          å¿…é ˆå¼•æ•°ã§ã‚ã‚‹ `rank` ã‚’æ¸¡ã™ã‚ˆã†ã«ä¿®æ­£ã€‚
# ä¿®æ­£(mypy): [list-item], [assignment], [arg-type] ã‚¨ãƒ©ãƒ¼ã‚’è§£æ¶ˆã€‚

from typing import Dict, Any, Optional, List, TYPE_CHECKING, Union # Union ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import asyncio
import os
from pathlib import Path
import torch
from omegaconf import OmegaConf, DictConfig # DictConfig ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import re
from collections import Counter
from heapq import nlargest
import json
try:
    from googlesearch import search  # type: ignore
except ImportError:
    print("âš ï¸ 'googlesearch-python' is not installed. Web search functionality will be limited. Please run 'pip install googlesearch-python'")
    def search(*args, **kwargs):
        return iter([])

from snn_research.distillation.model_registry import ModelRegistry
from snn_research.distillation.knowledge_distillation_manager import KnowledgeDistillationManager
from snn_research.tools.web_crawler import WebCrawler
from .memory import Memory as AgentMemory
from snn_research.deployment import SNNInferenceEngine
from snn_research.communication.spike_encoder_decoder import SpikeEncoderDecoder

# --- â–¼ ä¿®æ­£ â–¼ ---
if TYPE_CHECKING:
    from snn_research.cognitive_architecture.hierarchical_planner import HierarchicalPlanner
# --- â–² ä¿®æ­£ â–² ---


class AutonomousAgent:
    """
    è‡ªå¾‹çš„ã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹ã€‚
    """
    def __init__(
        self,
        name: str,
        # --- â–¼ ä¿®æ­£ â–¼ ---
        planner: "HierarchicalPlanner",
        # --- â–² ä¿®æ­£ â–² ---
        model_registry: ModelRegistry,
        memory: AgentMemory,
        web_crawler: WebCrawler,
        accuracy_threshold: float = 0.6,
        energy_budget: float = 10000.0
    ):
        self.name = name
        self.planner = planner
        self.model_registry = model_registry
        self.memory = memory
        self.web_crawler = web_crawler
        # --- â–¼ ä¿®æ­£ â–¼ ---
        # last_action, last_result ã¯è¾æ›¸å‹ã‚‚å—ã‘å…¥ã‚Œã‚‹ã‚ˆã†ã« Union ã‚’ä½¿ç”¨
        self.current_state: Dict[str, Union[str, Dict[str, Any], None]] = {
            "agent_name": name, "last_action": None, "last_result": None
        }
        # --- â–² ä¿®æ­£ â–² ---
        self.accuracy_threshold = accuracy_threshold
        self.energy_budget = energy_budget
        self.spike_communicator = SpikeEncoderDecoder()

    def receive_and_process_spike_message(self, spike_pattern: torch.Tensor, source_agent: str):
        """
        ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰é€ä¿¡ã•ã‚ŒãŸã‚¹ãƒ‘ã‚¤ã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã—ã€è§£é‡ˆã—ã¦è¨˜æ†¶ã™ã‚‹ã€‚
        """
        print(f"ğŸ“¡ Agent '{self.name}' received a spike message from '{source_agent}'.")
        decoded_message = self.spike_communicator.decode_data(spike_pattern)

        if decoded_message and isinstance(decoded_message, dict) and "error" not in decoded_message:
            print(f"  - Decoded Intent: {decoded_message.get('intent')}")
            print(f"  - Decoded Payload: {decoded_message.get('payload')}")

            # è¨˜æ†¶ã«è¨˜éŒ²
            self.memory.record_experience(
                state=self.current_state,
                action="receive_communication",
                result={"decoded_message": decoded_message, "source": source_agent},
                reward={"external": 0.2}, # é€šä¿¡æˆåŠŸãƒœãƒ¼ãƒŠã‚¹
                expert_used=["spike_communicator"],
                decision_context={"reason": "Inter-agent communication received."}
            )
            # ç¾åœ¨ã®çŠ¶æ…‹ã‚’æ›´æ–° (ä¾‹)
            self.current_state["last_communication"] = decoded_message
        else:
            # ãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
            raw_text = decoded_message if isinstance(decoded_message, str) else str(decoded_message)
            print(f"  - Failed to decode spike message. Raw content: {raw_text}")
            self.memory.record_experience(
                state=self.current_state,
                action="receive_communication_failed",
                result={"raw_content": raw_text, "source": source_agent},
                reward={"external": -0.1}, # ãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—ãƒšãƒŠãƒ«ãƒ†ã‚£
                expert_used=["spike_communicator"],
                decision_context={"reason": "Failed to decode incoming spike message."}
            )

    def execute(self, task_description: str) -> str:
        """
        ä¸ãˆã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã€‚ (handle_taskã¸ã®å§”è­²ã‚’æƒ³å®š)
        """
        print(f"Agent '{self.name}' received task: {task_description}")
        # å®Ÿéš›ã«ã¯ handle_task ã‚’å‘¼ã³å‡ºã™ã“ã¨ãŒå¤šã„
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«å®Ÿè¡Œãƒ­ã‚°ã‚’è¿”ã™
        result_info = asyncio.run(self.handle_task(task_description))

        expert_id_list: List[str] = [] # å‹ãƒ’ãƒ³ãƒˆè¿½åŠ 
        if result_info and result_info.get("path"):
            result = f"Task '{task_description}' handled by Agent '{self.name}'. Outcome: SUCCESS (Expert: {result_info.get('model_id')})"
            reward_val = 1.0
            if result_info.get('model_id'):
                 expert_id_list.append(str(result_info['model_id'])) # model_idãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèª
        elif result_info and "error" in result_info:
             result = f"Task '{task_description}' handled by Agent '{self.name}'. Outcome: FAILURE ({result_info.get('error')})"
             reward_val = -1.0
        else:
            result = f"Task '{task_description}' handled by Agent '{self.name}'. Outcome: SKIPPED/UNKNOWN"
            reward_val = 0.0


        self.memory.record_experience(
            state=self.current_state,
            action="execute_task",
            result={"status": "SUCCESS" if reward_val > 0 else "FAILURE", "details": result},
            reward={"external": reward_val},
            expert_used=expert_id_list, # ä¿®æ­£: list[str]ã‚’æ¸¡ã™
            decision_context={"reason": "Direct execution command received."},
            causal_snapshot=f"Executing task: {task_description}" # å› æœã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¾‹
        )
        self.current_state["last_action"] = "execute_task"
        self.current_state["last_result"] = result
        return result


    async def find_expert(self, task_description: str) -> Dict[str, Any] | None:
        """
        ã‚¿ã‚¹ã‚¯ã«æœ€é©ãªå°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰æ¤œç´¢ã™ã‚‹ã€‚
        """
        # ã‚¿ã‚¹ã‚¯è¨˜è¿°ã‚’æ­£è¦åŒ– (å°æ–‡å­—åŒ–ã€ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã«)
        safe_task_description = task_description.lower().replace(" ", "_").replace("/", "_")
        print(f"Searching for expert for task: {safe_task_description}")
        candidate_experts = await self.model_registry.find_models_for_task(safe_task_description, top_k=5)

        if not candidate_experts:
            print(f"æœ€é©ãªå°‚é–€å®¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {safe_task_description}")
            return None

        # ç²¾åº¦ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ã®åŸºæº–ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        suitable_experts = []
        for expert in candidate_experts:
            metrics = expert.get("metrics", {})
            accuracy = metrics.get("accuracy", 0.0)
            # handle potential missing key or None value for spikes
            spikes_value = metrics.get("avg_spikes_per_sample")
            spikes = float(spikes_value) if spikes_value is not None else float('inf')

            if accuracy >= self.accuracy_threshold and spikes <= self.energy_budget:
                suitable_experts.append(expert)

        if suitable_experts:
            # åŸºæº–ã‚’æº€ãŸã™ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã‹ã‚‰æœ€ã‚‚ç²¾åº¦ã®é«˜ã„ã‚‚ã®ã‚’é¸æŠ
            best_expert = max(suitable_experts, key=lambda x: x.get("metrics", {}).get("accuracy", 0.0))
            acc = best_expert.get("metrics", {}).get("accuracy", 0.0)
            spk = best_expert.get("metrics", {}).get("avg_spikes_per_sample", float('inf'))
            print(f"âœ… æ¡ä»¶ã‚’æº€ãŸã™æœ€é©ãªå°‚é–€å®¶ã‚’ç™ºè¦‹: {best_expert.get('model_id')} (Accuracy: {acc:.4f}, Spikes: {spk:.2f})")
            return best_expert
        else:
            # åŸºæº–ã‚’æº€ãŸã™ãƒ¢ãƒ‡ãƒ«ãŒãªã„å ´åˆã€æœ€ã‚‚ç²¾åº¦ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦è¿”ã™
            print(f"âš ï¸ å°‚é–€å®¶ã¯è¦‹ã¤ã‹ã‚Šã¾ã—ãŸãŒã€ç²¾åº¦/ã‚¨ãƒãƒ«ã‚®ãƒ¼è¦ä»¶ã‚’æº€ãŸã™ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            best_candidate = max(candidate_experts, key=lambda x: x.get("metrics", {}).get("accuracy", 0.0))
            acc = best_candidate.get("metrics", {}).get("accuracy", 0.0)
            spk = best_candidate.get("metrics", {}).get("avg_spikes_per_sample", float('inf'))
            print(f"   - æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ« (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯): {best_candidate.get('model_id')} (Accuracy: {acc:.4f}, Spikes: {spk:.2f})")
            print(f"   - (è¦ä»¶: accuracy >= {self.accuracy_threshold}, spikes <= {self.energy_budget})")
            return best_candidate

    def learn_from_web(self, topic: str) -> str:
        """
        Webã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’ä½¿ã£ã¦æƒ…å ±ã‚’åé›†ã—ã€çŸ¥è­˜ã‚’æ›´æ–°ã™ã‚‹ã€‚(ç¾åœ¨ã¯è¦ç´„ã®ã¿)
        """
        print(f"Agent '{self.name}' is learning about '{topic}' from the web.")
        urls = self._search_for_urls(topic)
        task_name = f"learn_from_web_{topic.replace(' ', '_')}" # ã‚¿ã‚¹ã‚¯åã‚’ç”Ÿæˆ
        if not urls:
            result_details = "Could not find relevant information on the web."
            self.memory.record_experience(
                state=self.current_state, action=task_name,
                result={"status": "FAILURE", "details": result_details},
                reward={"external": -0.5}, # å°‘ã—ä½ã„ãƒšãƒŠãƒ«ãƒ†ã‚£
                expert_used=["web_crawler"],
                decision_context={"reason": "No relevant URLs found during web search."},
                causal_snapshot=f"Web search for '{topic}' failed."
            )
            self.current_state["last_action"] = task_name
            # --- â–¼ ä¿®æ­£ â–¼ ---
            self.current_state["last_result"] = {"status": "FAILURE", "details": result_details}
            # --- â–² ä¿®æ­£ â–² ---
            return result_details

        all_content = ""
        # åé›†ã™ã‚‹URLæ•°ã‚’åˆ¶é™ (ä¾‹: æœ€åˆã®2ã¤)
        for url in urls[:2]:
            print(f"Crawling URL: {url}")
            # ã‚¯ãƒ­ãƒ¼ãƒ«å®Ÿè¡Œ (ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–)
            try:
                crawled_data_path = self.web_crawler.crawl(url, max_pages=1) # 1ãƒšãƒ¼ã‚¸ã ã‘å–å¾—
                if crawled_data_path and os.path.exists(crawled_data_path):
                     with open(crawled_data_path, 'r', encoding='utf-8') as f:
                        for line in f:
                            try:
                                content_data = json.loads(line)
                                all_content += content_data.get('text', '') + "\n\n"
                            except json.JSONDecodeError:
                                print(f"Warning: Skipping invalid JSON line in {crawled_data_path}")
            except Exception as e:
                 print(f"Error crawling {url}: {e}")


        if not all_content.strip():
             result_details = "Crawled content was empty or could not be processed."
             self.memory.record_experience(
                state=self.current_state, action=task_name,
                result={"status": "FAILURE", "details": result_details},
                reward={"external": -0.3},
                expert_used=["web_crawler"],
                decision_context={"reason": "Crawled content was empty."},
                causal_snapshot=f"Crawling for '{topic}' yielded no content."
             )
             self.current_state["last_action"] = task_name
             # --- â–¼ ä¿®æ­£ â–¼ ---
             self.current_state["last_result"] = {"status": "FAILURE", "details": result_details}
             # --- â–² ä¿®æ­£ â–² ---
             return result_details


        summary = self._summarize(all_content)

        self.memory.record_experience(
            state=self.current_state, action=task_name,
            result={"status": "SUCCESS", "summary": summary, "source_urls": urls[:2]},
            reward={"external": 0.8}, # æƒ…å ±åé›†æˆåŠŸãƒœãƒ¼ãƒŠã‚¹
            expert_used=["web_crawler", "summarizer"], # ä»®ã®summarizer
            decision_context={"reason": "Information successfully retrieved and summarized from the web."},
            causal_snapshot=f"Successfully learned about '{topic}' from web."
        )
        self.current_state["last_action"] = task_name
        # --- â–¼ ä¿®æ­£ â–¼ ---
        self.current_state["last_result"] = {"status": "SUCCESS", "summary": summary}
        # --- â–² ä¿®æ­£ â–² ---
        return f"Successfully learned about '{topic}'. Summary: {summary}"

    def _search_for_urls(self, query: str) -> list[str]:
        """
        æŒ‡å®šã•ã‚ŒãŸã‚¯ã‚¨ãƒªã§Webã‚’æ¤œç´¢ã—ã€é–¢é€£ã™ã‚‹URLã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
        """
        print(f"ğŸ” Searching the web for: '{query}'")
        try:
            # googlesearchãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨
            # num_results ã‚’ 3 ã«å¤‰æ›´
            urls = list(search(query, num_results=3, lang="ja")) # æ—¥æœ¬èªæ¤œç´¢ã‚’æŒ‡å®š
            print(f"âœ… Found {len(urls)} relevant URLs.")
            if not urls:
                 print("No URLs found via search, using fallback.")
                 # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯URL (ä¾‹)
                 urls = [
                     'https://www.nature.com/articles/s41583-024-00888-x',
                     'https://www.frontiersin.org/articles/10.3389/fnins.2023.1209795/full',
                 ]
            return urls
        except Exception as e:
            print(f"âŒ Web search failed: {e}. Using fallback URLs.")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯URLã‚’è¿”ã™
            return [
                'https://www.nature.com/articles/s41583-024-00888-x',
                'https://www.frontiersin.org/articles/10.3389/fnins.2023.1209795/full',
            ]

    def _summarize(self, text: str) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã€‚ï¼ˆç¾åœ¨ã¯ç°¡æ˜“å®Ÿè£…ï¼‰
        å°†æ¥çš„ã«ã¯å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã™ã€‚
        """
        print("âœï¸ Summarizing content...")
        if not text:
            return "(No content to summarize)"

        summarizer_expert = asyncio.run(self.find_expert("æ–‡ç« è¦ç´„")) # find_expertã¯éåŒæœŸãªã®ã§await

        if not summarizer_expert:
            print("âš ï¸ Summarization expert not found. Using basic extractive summary.")
            sentences = re.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|ã€‚)\s', text.strip()) # æ—¥æœ¬èªå¥ç‚¹ã‚‚è€ƒæ…®
            sentences = [s for s in sentences if s] # ç©ºã®æ–‡ã‚’å‰Šé™¤
            if not sentences: return "(Could not extract sentences)"

            words = re.findall(r'\b\w+\b', text.lower()) # ç°¡å˜ãªå˜èªåˆ†å‰²
            if not words: return "(Could not extract words)"

            word_freq = Counter(words)
            # ã‚¹ã‚³ã‚¢è¨ˆç®—: æ–‡ä¸­ã®å˜èªé »åº¦ã®åˆè¨ˆ / æ–‡ã®é•·ã• (å˜ç´”åŒ–)
            sentence_scores: Dict[int, float] = {}
            for i, s in enumerate(sentences):
                 s_words = re.findall(r'\b\w+\b', s.lower())
                 score = sum(word_freq[word] for word in s_words)
                 length = len(s_words)
                 sentence_scores[i] = score / (length + 1e-5) # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢

            # ã‚¹ã‚³ã‚¢ä¸Šä½3æ–‡ã‚’é¸æŠ
            num_summary_sentences = min(3, len(sentences))
            # --- â–¼ ä¿®æ­£ â–¼ ---
            # nlargest ã® key å¼•æ•°ã«ã¯ callable ã‚’æ¸¡ã™
            highest_scoring_indices = nlargest(num_summary_sentences, sentence_scores, key=lambda k: sentence_scores[k])
            # --- â–² ä¿®æ­£ â–² ---

            # å…ƒã®é †åºã§çµåˆ
            summary = " ".join([sentences[i] for i in sorted(highest_scoring_indices)])
            return summary
        else:
            print(f"âœ… Found summarization expert: {summarizer_expert.get('model_id')}")
            # å®Ÿéš›ã«ã¯ã“ã“ã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹
            # summary_result = asyncio.run(self.run_inference(summarizer_expert, text)) # run_inferenceã‚’å‘¼ã³å‡ºã™
            # ãƒ€ãƒŸãƒ¼å¿œç­”
            summary_result = f"(Summary generated by expert '{summarizer_expert.get('model_id')}'): " + " ".join(text.split()[:30]) + "..."
            return summary_result


    async def handle_task(self, task_description: str, unlabeled_data_path: Optional[str] = None, force_retrain: bool = False) -> Optional[Dict[str, Any]]:
        """
        ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã™ã‚‹ä¸­å¿ƒçš„ãªãƒ¡ã‚½ãƒƒãƒ‰ã€‚å°‚é–€å®¶ã‚’æ¤œç´¢ã—ã€ã„ãªã‘ã‚Œã°å­¦ç¿’ã‚’è©¦ã¿ã‚‹ã€‚
        """
        print(f"--- Handling Task: {task_description} ---")
        # é–‹å§‹æ™‚ã«çŠ¶æ…‹ã‚’è¨˜éŒ²
        self.memory.record_experience(
             state=self.current_state,
             action="handle_task_start",
             result={"task": task_description},
             reward={"external": 0.0},
             expert_used=[],
             decision_context={"reason": "Task received by agent."}
        )

        expert_model: Optional[Dict[str, Any]] = None
        if not force_retrain:
            candidate_expert = await self.find_expert(task_description)
            if candidate_expert:
                # find_expertå†…ã§ãƒ­ã‚°å‡ºåŠ›æ¸ˆã¿ãªã®ã§ã“ã“ã§ã¯çœç•¥
                expert_model = candidate_expert # find_expertã¯æœ€é©ãªã‚‚ã®(ãªã‘ã‚Œã°None)ã‚’è¿”ã™

        if expert_model:
             # å°‚é–€å®¶ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ
             self.current_state["last_action"] = "expert_found"
             self.current_state["last_result"] = expert_model.get("model_id")
             # å¿…è¦ã§ã‚ã‚Œã°ã“ã“ã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ 
             # await self.run_inference(expert_model, "some default prompt or context")
             return expert_model # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¿”ã™


        # å°‚é–€å®¶ãŒã„ãªã„ã€ã¾ãŸã¯å†å­¦ç¿’ãŒå¼·åˆ¶ã•ã‚Œã‚‹å ´åˆ
        if unlabeled_data_path:
            print("- No suitable expert found or retraining forced. Initiating on-demand learning...")
            try:
                # DIã‚³ãƒ³ãƒ†ãƒŠã®å–å¾— (ä¾å­˜é–¢ä¿‚è§£æ±ºã®ãŸã‚)
                # æ³¨: æœ¬æ¥ã¯AgentåˆæœŸåŒ–æ™‚ã«DIã‚³ãƒ³ãƒ†ãƒŠã‹å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å—ã‘å–ã‚‹ã¹ã
                from app.containers import TrainingContainer # ã“ã“ã§ã®importã¯ç†æƒ³çš„ã§ã¯ãªã„
                container = TrainingContainer()
                # å¿…è¦ãªè¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰
                container.config.from_yaml("configs/base_config.yaml")
                # ãƒ¢ãƒ‡ãƒ«è¨­å®šã¯ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦å‹•çš„ã«é¸æŠã™ã‚‹æ–¹ãŒè‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„
                container.config.from_yaml("configs/models/medium.yaml") # ä»®ã«mediumã‚’ä½¿ç”¨

                # å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å–å¾—
                device = container.device()
                student_model = container.snn_model().to(device) # vocab_sizeã¯ä¸­ã§å–å¾—ã•ã‚Œã‚‹æƒ³å®š
                optimizer = container.optimizer(params=student_model.parameters())
                scheduler = container.scheduler(optimizer=optimizer) if container.config.training.gradient_based.use_scheduler() else None

                distillation_trainer = container.distillation_trainer(
                    model=student_model,
                    optimizer=optimizer,
                    scheduler=scheduler,
                    device=device,
                    rank=-1  # éåˆ†æ•£å­¦ç¿’ã®ãŸã‚rankã‚’-1ã«è¨­å®š
                )

                # Managerã®åˆæœŸåŒ–ã«å¿…è¦ãªconfigã‚’å–å¾—
                manager_config = container.config()

                manager = KnowledgeDistillationManager(
                    student_model=student_model,
                    trainer=distillation_trainer,
                    tokenizer_name=container.config.data.tokenizer_name(),
                    model_registry=self.model_registry,
                    device=device,
                    config=manager_config # configã‚’æ¸¡ã™
                    # teacher_model_name ã¯ manager å†…ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§configã‹ã‚‰å–å¾—ã•ã‚Œã‚‹
                )

                # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®é¸æŠãƒ­ã‚¸ãƒƒã‚¯
                wikitext_path = "data/wikitext-103_train.jsonl"
                learning_data_path: str
                if os.path.exists(wikitext_path):
                    print(f"âœ… å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{wikitext_path}' ã‚’ç™ºè¦‹ã€‚æœ¬æ ¼çš„ãªå­¦ç¿’ã«ä½¿ç”¨ã—ã¾ã™ã€‚")
                    learning_data_path = wikitext_path
                else:
                    learning_data_path = unlabeled_data_path
                    print(f"âš ï¸ å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æŒ‡å®šã•ã‚ŒãŸ '{learning_data_path}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

                # å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’å–å¾—
                student_model_config = container.config.model.to_dict()

                # ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
                new_model_info = await manager.run_on_demand_pipeline(
                    task_description=task_description,
                    unlabeled_data_path=learning_data_path,
                    force_retrain=force_retrain, # force_retrainå¼•æ•°ã‚’æ¸¡ã™
                    student_config=student_model_config
                )

                # --- â–¼ ä¿®æ­£: model_id ã‚’å®‰å…¨ã«æ–‡å­—åˆ—åŒ– â–¼ ---
                model_id_val = new_model_info.get('model_id') if new_model_info else None
                model_id_str = str(model_id_val) if model_id_val is not None else "unknown"
                reward_val = 1.0 if new_model_info and "error" not in new_model_info else -0.8
                
                self.memory.record_experience(
                    state=self.current_state,
                    action="on_demand_learning",
                    result=new_model_info if new_model_info else {"error": "Training pipeline failed to return info"},
                    reward={"external": reward_val},
                    expert_used=[model_id_str] if model_id_str != "unknown" else [], # ä¿®æ­£: model_id_str ã‚’ä½¿ç”¨
                    decision_context={"reason": "Attempted to create a new expert for the task."},
                    causal_snapshot=f"On-demand learning for '{task_description}' completed."
                 )
                # --- â–² ä¿®æ­£ â–² ---
                self.current_state["last_action"] = "on_demand_learning"
                # --- â–¼ ä¿®æ­£ â–¼ ---
                self.current_state["last_result"] = new_model_info if new_model_info else {"error": "Training pipeline failed"}
                return new_model_info

            except Exception as e:
                print(f"âŒ On-demand learning failed: {e}")
                import traceback
                traceback.print_exc() # è©³ç´°ãªã‚¨ãƒ©ãƒ¼ã‚’å‡ºåŠ›
                error_info = {"error": str(e)}
                self.memory.record_experience(
                     state=self.current_state,
                     action="on_demand_learning_error",
                     result=error_info,
                     reward={"external": -1.0}, # é‡ã„ãƒšãƒŠãƒ«ãƒ†ã‚£
                     expert_used=[],
                     decision_context={"reason": "An unexpected error occurred during training."},
                     causal_snapshot=f"Critical error during on-demand learning for '{task_description}'."
                 )
                self.current_state["last_action"] = "on_demand_learning_error"
                # --- â–¼ ä¿®æ­£ â–¼ ---
                self.current_state["last_result"] = error_info
                # --- â–² ä¿®æ­£ â–² ---
                return error_info # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¿”ã™

        # å°‚é–€å®¶ãŒè¦‹ã¤ã‹ã‚‰ãšã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚‚ãªã„å ´åˆ
        print("- No expert found and no unlabeled data provided for training.")
        no_expert_info = {"status": "skipped", "reason": "No expert found and no data for training."}
        self.memory.record_experience(
            state=self.current_state,
            action="handle_task_skipped",
            result=no_expert_info,
            reward={"external": -0.1}, # è»½ã„ãƒšãƒŠãƒ«ãƒ†ã‚£
            expert_used=[],
            decision_context={"reason": "Unable to proceed with the task."},
            causal_snapshot=f"Skipped task '{task_description}' due to lack of expert/data."
        )
        self.current_state["last_action"] = "handle_task_skipped"
        # --- â–¼ ä¿®æ­£ â–¼ ---
        self.current_state["last_result"] = no_expert_info
        # --- â–² ä¿®æ­£ â–² ---
        return no_expert_info # ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ã‚’è¿”ã™

    async def run_inference(self, model_info: Dict[str, Any], prompt: str) -> None:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
        """
        model_id = model_info.get('model_id', 'N/A')
        model_path = model_info.get('model_path') or model_info.get('path')
        model_config = model_info.get('config') # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰configã‚’å–å¾—

        print(f"\n--- Running Inference ---")
        print(f"Model ID: {model_id}")
        print(f"Model Path: {model_path}")
        print(f"Prompt: {prompt}")

        if not model_path or not os.path.exists(model_path):
            print(f"âŒ Error: Model file not found at '{model_path}'. Cannot run inference.")
            self.memory.record_experience(self.current_state, "inference_error", {"error": "Model file not found"}, {"external": -0.5}, [model_id], {})
            self.current_state["last_action"] = "inference_error"
            # --- â–¼ ä¿®æ­£ â–¼ ---
            self.current_state["last_result"] = {"error": "Model file not found"}
            # --- â–² ä¿®æ­£ â–² ---
            return

        if not model_config:
            print("âŒ Error: Model config not found in model_info. Cannot initialize inference engine.")
            self.memory.record_experience(self.current_state, "inference_error", {"error": "Model config not found"}, {"external": -0.5}, [model_id], {})
            self.current_state["last_action"] = "inference_error"
            # --- â–¼ ä¿®æ­£ â–¼ ---
            self.current_state["last_result"] = {"error": "Model config not found"}
            # --- â–² ä¿®æ­£ â–² ---
            return

        try:
            # æ¨è«–ç”¨ã®è¨­å®šã‚’ä½œæˆ
            # ãƒ™ãƒ¼ã‚¹è¨­å®šã®ä¸€éƒ¨ã¨ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ãƒãƒ¼ã‚¸
            # ã“ã“ã§ã¯ DI ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ã‚ãšç›´æ¥è¨­å®šã‚’ä½œæˆã™ã‚‹ä¾‹
            inference_config_dict = {
                'device': 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu',
                'data': {
                    'tokenizer_name': "gpt2" # ä»®ã€‚æœ¬æ¥ã¯ãƒ¢ãƒ‡ãƒ«ã«ç´ã¥ãã¹ã
                },
                'model': model_config # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰å–å¾—ã—ãŸconfigã‚’ä½¿ç”¨
            }
            # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«ã—ã¦è¨­å®šã«è¿½åŠ 
            absolute_path = str(Path(model_path).resolve())
            inference_config_dict['model']['path'] = absolute_path

            inference_config = OmegaConf.create(inference_config_dict)

            # æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
            inference_engine = SNNInferenceEngine(config=inference_config)

            # æ¨è«–å®Ÿè¡Œã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›
            full_response = ""
            print("Response Stream: ", end="", flush=True)
            for chunk, stats in inference_engine.generate(prompt, max_len=50): # max_lenã¯é©å®œèª¿æ•´
                print(chunk, end="", flush=True)
                full_response += chunk
            print("\n--- Inference Complete ---")

            # æˆåŠŸè¨˜éŒ²
            self.memory.record_experience(
                 state=self.current_state,
                 action="inference_success",
                 result={"prompt": prompt, "response": full_response, "stats": inference_engine.last_inference_stats},
                 reward={"external": 0.5}, # æ¨è«–æˆåŠŸãƒœãƒ¼ãƒŠã‚¹
                 expert_used=[model_id],
                 decision_context={"reason": f"Successfully generated response using expert '{model_id}'."},
                 causal_snapshot=f"Inference using '{model_id}' for prompt '{prompt[:20]}...' succeeded."
            )
            self.current_state["last_action"] = "inference_success"
            # --- â–¼ ä¿®æ­£ â–¼ ---
            self.current_state["last_result"] = {"response": full_response}
            # --- â–² ä¿®æ­£ â–² ---


        except Exception as e:
            print(f"\nâŒ Inference failed: {e}")
            import traceback
            traceback.print_exc()
            error_info = {"error": str(e), "model_id": model_id, "prompt": prompt}
            # å¤±æ•—è¨˜éŒ²
            self.memory.record_experience(
                state=self.current_state,
                action="inference_error",
                result=error_info,
                reward={"external": -0.7}, # æ¨è«–å¤±æ•—ãƒšãƒŠãƒ«ãƒ†ã‚£
                expert_used=[model_id],
                decision_context={"reason": f"An error occurred during inference with expert '{model_id}'."},
                causal_snapshot=f"Inference using '{model_id}' failed."
            )
            self.current_state["last_action"] = "inference_error"
            # --- â–¼ ä¿®æ­£ â–¼ ---
            self.current_state["last_result"] = error_info
            # --- â–² ä¿®æ­£ â–² ---
