# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/hybrid_perception_cortex.py
# (æ›´æ–°)
# ä¿®æ­£: mypyã‚¨ãƒ©ãƒ¼ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€Optionalå‹ã‚’æ˜ç¤ºçš„ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ»ä½¿ç”¨ã€‚
# æ”¹å–„ç‚¹(v2): ã€Œæ„è­˜çš„èªçŸ¥ã‚µã‚¤ã‚¯ãƒ«ã€å®Ÿè£…ã®ãŸã‚ã€GlobalWorkspaceã¨é€£æºã€‚
#            - å‡¦ç†çµæœã‚’è¿”ã™ã®ã§ã¯ãªãã€é¡•è‘—æ€§ã‚¹ã‚³ã‚¢ã¨å…±ã«Workspaceã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
#            - é¡•è‘—æ€§ã‚¹ã‚³ã‚¢ã¨ã—ã¦ã€å…¥åŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ´»å‹•é‡ï¼ˆç·ã‚¹ãƒ‘ã‚¤ã‚¯æ•°ï¼‰ã‚’åˆ©ç”¨ã™ã‚‹ã€‚

import torch
from typing import Dict, Any, Optional

from .som_feature_map import SomFeatureMap
from .global_workspace import GlobalWorkspace

class HybridPerceptionCortex:
    """
    è‡ªå·±çµ„ç¹”åŒ–ãƒãƒƒãƒ—(SOM)ã‚’çµ±åˆã—ã€GlobalWorkspaceã¨é€£æºã™ã‚‹çŸ¥è¦šé‡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
    """
    def __init__(self, workspace: GlobalWorkspace, num_neurons: int, feature_dim: int = 64, som_map_size=(8, 8), stdp_params: Optional[Dict[str, Any]] = None):
        """
        Args:
            workspace (GlobalWorkspace): æƒ…å ±ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ä¸­å¤®ãƒãƒ–ã€‚
            num_neurons (int): å…¥åŠ›ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°ã€‚
            feature_dim (int): SOMã¸ã®å…¥åŠ›ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°ã€‚
            som_map_size (tuple): SOMã®ãƒãƒƒãƒ—ã‚µã‚¤ã‚ºã€‚
            stdp_params (Optional[dict]): SOMãŒä½¿ç”¨ã™ã‚‹STDPå­¦ç¿’å‰‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚
        """
        self.workspace = workspace
        self.num_neurons = num_neurons
        self.feature_dim = feature_dim
        
        self.input_projection = torch.randn((num_neurons, feature_dim))
        
        if stdp_params is None:
            stdp_params = {'learning_rate': 0.005, 'a_plus': 1.0, 'a_minus': 1.0, 'tau_trace': 20.0}
        
        self.som = SomFeatureMap(
            input_dim=feature_dim,
            map_size=som_map_size,
            stdp_params=stdp_params
        )
        print("ğŸ§  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰çŸ¥è¦šé‡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ (SOMçµ±åˆ)ã€‚")

    def perceive_and_upload(self, spike_pattern: torch.Tensor) -> None:
        """
        å…¥åŠ›ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’çŸ¥è¦šãƒ»å­¦ç¿’ã—ã€ãã®çµæœã¨é¡•è‘—æ€§ã‚’GlobalWorkspaceã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
        """
        if spike_pattern.shape[1] != self.num_neurons:
            raise ValueError(f"å…¥åŠ›ã‚¹ãƒ‘ã‚¤ã‚¯ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•° ({spike_pattern.shape[1]}) ãŒ"
                             f"çŸ¥è¦šé‡ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•° ({self.num_neurons}) ã¨ä¸€è‡´ã—ã¾ã›ã‚“ã€‚")

        # 1. æ™‚é–“çš„ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        temporal_features = torch.sum(spike_pattern, dim=0)

        # 2. ç‰¹å¾´å°„å½±
        feature_vector = torch.matmul(temporal_features, self.input_projection)
        feature_vector = torch.relu(feature_vector)

        # 3. SOMã«ã‚ˆã‚‹ç‰¹å¾´åˆ†é¡ã¨å­¦ç¿’
        for _ in range(5):
            som_spikes = self.som(feature_vector)
            self.som.update_weights(feature_vector, som_spikes)
        
        final_som_activation = self.som(feature_vector)
        
        # é¡•è‘—æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆå…¥åŠ›ã‚¹ãƒ‘ã‚¤ã‚¯ã®ç·é‡ï¼åˆºæ¿€ã®å¼·ã•ï¼‰
        salience = torch.sum(spike_pattern).item() / spike_pattern.numel()
        
        perception_data = {"type": "perception", "features": final_som_activation}

        self.workspace.upload_to_workspace(
            source="perception",
            data=perception_data,
            salience=salience
        )
        print(f"  - çŸ¥è¦šé‡: ç‰¹å¾´ã‚’æŠ½å‡ºã—ã€Workspaceã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")