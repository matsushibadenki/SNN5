# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/basal_ganglia.py
# (æ›´æ–°)
# ã‚¿ã‚¤ãƒˆãƒ«: å¤§è„³åŸºåº•æ ¸ï¼šæƒ…å‹•å¤‰èª¿ã‚’ä¼´ã†è¡Œå‹•é¸æŠãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
# æ©Ÿèƒ½èª¬æ˜:
# - è„³ã®ç›´æ¥è·¯ï¼ˆGoï¼‰ã¨é–“æ¥è·¯ï¼ˆNoGoï¼‰ã®æ©Ÿèƒ½ã‚’æ¨¡å€£ã—ã€è¤‡æ•°ã®é¸æŠè‚¢ã‹ã‚‰æœ€é©ãªè¡Œå‹•ã‚’æ±ºå®šã™ã‚‹ã€‚
# - Amygdalaã‹ã‚‰å—ã‘å–ã£ãŸæƒ…å‹•ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¿«ãƒ»ä¸å¿«ã€è¦šé†’ãƒ»æ²ˆé™ï¼‰ã«åŸºã¥ãã€
#   æ„æ€æ±ºå®šã®é–¾å€¤ã‚’å‹•çš„ã«èª¿æ•´ã™ã‚‹ã€‚ä¾‹ãˆã°ã€å±é™ºã‚’å¯ŸçŸ¥ã—ãŸå ´åˆï¼ˆä¸å¿«ãƒ»é«˜è¦šé†’ï¼‰ã€
#   ã‚ˆã‚Šè¿…é€Ÿã«è¡Œå‹•ã‚’èµ·ã“ã›ã‚‹ã‚ˆã†ã«é–¾å€¤ã‚’ä¸‹ã’ã‚‹ã€‚
# - å®Ÿè¡Œãƒ­ã‚°ã‚’å¼·åŒ–ã—ã€æƒ…å‹•ãŒæ„æ€æ±ºå®šã«ä¸ãˆãŸå½±éŸ¿ã‚’æ˜ç¢ºã«è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã«ã—ãŸã€‚
#
# æ”¹å–„ç‚¹(v2):
# - ã€Œæ„è­˜çš„èªçŸ¥ã‚µã‚¤ã‚¯ãƒ«ã€å®Ÿè£…ã®ãŸã‚ã€GlobalWorkspaceã¨é€£æºã€‚
# - ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã•ã‚ŒãŸã€Œæ„è­˜çš„æƒ…å ±ã€ã‚’è³¼èª­ã—ã€è¡Œå‹•é¸æŠã®ãƒˆãƒªã‚¬ãƒ¼ã¨ã™ã‚‹ã€‚

from typing import List, Dict, Any, Optional
import torch
import torch.nn.functional as F

from .global_workspace import GlobalWorkspace

class BasalGanglia:
    """
    ä¾¡å€¤ä¿¡å·ã¨æƒ…å‹•æ–‡è„ˆã«åŸºã¥ã„ã¦è¡Œå‹•é¸æŠã‚’è¡Œã†å¤§è„³åŸºåº•æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
    """
    def __init__(self, workspace: GlobalWorkspace, selection_threshold: float = 0.5, inhibition_strength: float = 0.3):
        """
        Args:
            workspace (GlobalWorkspace): æƒ…å ±ã‚’è³¼èª­ã™ã‚‹ãŸã‚ã®ä¸­å¤®ãƒãƒ–ã€‚
            selection_threshold (float): è¡Œå‹•ã‚’å®Ÿè¡Œã«ç§»ã™ãŸã‚ã®åŸºæœ¬çš„ãªæ´»æ€§åŒ–ãƒ¬ãƒ™ãƒ«ã€‚
            inhibition_strength (float): é¸æŠã•ã‚Œãªã‹ã£ãŸè¡Œå‹•ã«å¯¾ã™ã‚‹æŠ‘åˆ¶ã®å¼·ã•ã€‚
        """
        self.workspace = workspace
        self.base_threshold = selection_threshold
        self.inhibition_strength = inhibition_strength
        self.selected_action: Optional[Dict[str, Any]] = None
        
        # æ„è­˜çš„æƒ…å ±ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦è‡ªèº«ã‚’è³¼èª­
        self.workspace.subscribe(self.handle_conscious_broadcast)
        print("ğŸ§  å¤§è„³åŸºåº•æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã€Workspaceã‚’è³¼èª­ã—ã¾ã—ãŸã€‚")

    def handle_conscious_broadcast(self, source: str, conscious_data: Dict[str, Any]):
        """
        GlobalWorkspaceã‹ã‚‰ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã•ã‚ŒãŸæ„è­˜çš„æƒ…å ±ã‚’å—ã‘å–ã‚Šã€è¡Œå‹•é¸æŠã®ãƒˆãƒªã‚¬ãƒ¼ã¨ã™ã‚‹ã€‚
        """
        print(f"ğŸ“¬ å¤§è„³åŸºåº•æ ¸: '{source}' ã‹ã‚‰ã®æ„è­˜çš„æƒ…å ±ã‚’å—ä¿¡ã€‚è¡Œå‹•é¸æŠã‚’è©•ä¾¡ã—ã¾ã™ã€‚")
        
        # ã“ã“ã§ã¯ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‹ã‚‰ã®è¡Œå‹•å€™è£œã‚’ãƒ€ãƒŸãƒ¼ã§ç”Ÿæˆ
        # å°†æ¥çš„ã«PlannerãŒWorkspaceã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸã‚‚ã®ã‚’åˆ©ç”¨ã™ã‚‹
        candidates = [
            {'action': 'investigate_perception', 'value': 0.8},
            {'action': 'reflect_on_emotion', 'value': 0.7},
            {'action': 'ignore', 'value': 0.3},
        ]
        
        emotion_context = conscious_data if conscious_data.get("type") == "emotion" else None
        
        self.select_action(candidates, emotion_context=emotion_context)

    def _modulate_threshold(self, emotion_context: Optional[Dict[str, float]]) -> float:
        """æƒ…å‹•çŠ¶æ…‹ã«åŸºã¥ã„ã¦è¡Œå‹•é¸æŠã®é–¾å€¤ã‚’å‹•çš„ã«èª¿æ•´ã™ã‚‹ã€‚"""
        if emotion_context is None:
            return self.base_threshold

        valence = emotion_context.get("valence", 0.0)
        arousal = emotion_context.get("arousal", 0.0)
        
        arousal_effect = -arousal * 0.2
        valence_effect = -valence * arousal * 0.1
        
        modulated_threshold = self.base_threshold + arousal_effect + valence_effect
        final_threshold = max(0.1, min(0.9, modulated_threshold))
        
        if final_threshold != self.base_threshold:
            print(f"  - å¤§è„³åŸºåº•æ ¸: æƒ…å‹•ã«ã‚ˆã‚Šé–¾å€¤ã‚’èª¿æ•´ ({self.base_threshold:.2f} -> {final_threshold:.2f})")
        
        return final_threshold

    def select_action(
        self, 
        action_candidates: List[Dict[str, Any]],
        emotion_context: Optional[Dict[str, float]] = None
    ) -> Optional[Dict[str, Any]]:
        """
        æç¤ºã•ã‚ŒãŸè¡Œå‹•å€™è£œã®ä¸­ã‹ã‚‰ã€å®Ÿè¡Œã™ã¹ãæœ€é©ãªè¡Œå‹•ã‚’ä¸€ã¤é¸æŠã™ã‚‹ã€‚
        """
        self.selected_action = None # å‰å›ã®é¸æŠã‚’ãƒªã‚»ãƒƒãƒˆ
        if not action_candidates:
            print("ğŸ¤” å¤§è„³åŸºåº•æ ¸: è¡Œå‹•å€™è£œãŒæç¤ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None
            
        current_threshold = self._modulate_threshold(emotion_context)

        values = torch.tensor([candidate.get('value', 0.0) for candidate in action_candidates])
        print(f"  - å¤§è„³åŸºåº•æ ¸: æ¤œè¨ä¸­ã®è¡Œå‹•å€™è£œ: {[c.get('action') for c in action_candidates]}, ä¾¡å€¤: {[round(v.item(), 2) for v in values]}")

        best_action_index = torch.argmax(values)
        best_action_value = values[best_action_index]

        if best_action_value >= current_threshold:
            self.selected_action = action_candidates[best_action_index]
            print(f"ğŸ† è¡Œå‹•é¸æŠ: '{self.selected_action.get('action')}' (æ´»æ€§å€¤: {best_action_value:.2f}, é–¾å€¤: {current_threshold:.2f})")
            return self.selected_action
        else:
            print(f"ğŸ¤” è¡Œå‹•æ£„å´: ã©ã®è¡Œå‹•ã‚‚å®Ÿè¡Œé–¾å€¤ ({current_threshold:.2f}) ã«é”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚(æœ€å¤§æ´»æ€§å€¤: {best_action_value:.2f})")
            return None