# ファイルパス: configs/base_config.yaml
# コードの最も最初には、ファイルパス、ファイルの内容を示したタイトル、機能の説明を詳細に記述してください。 修正内容は記載する必要はありません。
# Title: プロジェクト基本設定
# Description: 学習、データ、モデルレジストリなどの基本設定を管理。
# 改善点(v1): 知識蒸留の学習率を調整し、損失の重みを変更。
# 改善点(v2): probabilistic_neuron の設定を追加。

# 共通設定
seed: 42
device: "auto"

# データ設定
data:
  path: "data/sample_data.jsonl"
  format: "simple_text"
  split_ratio: 0.1
  max_vocab_size: 50000
  tokenizer_name: "gpt2"

# 学習パラメータ設定
training:
  paradigm: "gradient_based" # デフォルトをgradient_basedに変更
  epochs: 15 # デフォルトのエポック数を増やす
  batch_size: 16 # バッチサイズを少し増やす

  quantization:
    enabled: false
    backend: 'fbgemm'

  pruning:
    enabled: false
    amount: 0.2

  meta_cognition:
    enabled: true
    error_threshold: 0.8
    modulation_strength: 0.05

  planner:
    learning_rate: 0.001
    model_path: "runs/planner/best_model.pth"

  gradient_based:
    type: "distillation" # デフォルトを知識蒸留に
    learning_rate: 0.0005 # 学習率を少し下げる
    use_scheduler: true
    grad_clip_norm: 1.0
    use_amp: true
    warmup_epochs: 2 # ウォームアップエポックを追加
    loss:
      ce_weight: 1.0
      spike_reg_weight: 0.001
      sparsity_reg_weight: 0.00001
      mem_reg_weight: 0.0
      temporal_compression_weight: 0.001
      sparsity_threshold_reg_weight: 0.0001
      ewc_weight: 400.0
    distillation:
      teacher_model: "gpt2" # デフォルト教師 (run_distillation.pyで上書きされる)
      loss:
        ce_weight: 0.2 # CE損失の重みを少し下げる
        distill_weight: 0.8 # 蒸留損失の重みを上げる
        spike_reg_weight: 0.0005 # スパイク正則化を少し弱める
        sparsity_reg_weight: 0.000005 # スパース正則化を少し弱める
        mem_reg_weight: 0.0
        temporal_compression_weight: 0.0
        sparsity_threshold_reg_weight: 0.0
        temperature: 2.5 # 温度を少し上げる

  biologically_plausible:
    learning_rule: "CAUSAL_TRACE"
    adaptive_causal_sparsification:
      enabled: false
      contribution_threshold: 0.01
    particle_filter:
      enabled: false
      num_particles: 20
      noise_std: 0.05
    neuron:
      tau_mem: 10.0
      v_threshold: 1.0
      v_reset: 0.0
      v_rest: 0.0
      threshold_decay: 0.99
      threshold_step: 0.05
    stdp:
      tau_trace: 20.0
      learning_rate: 0.005
      a_plus: 1.0
      a_minus: 1.0
    reward_modulated_stdp:
      tau_eligibility: 100.0
      learning_rate: 0.01
    causal_trace:
      tau_eligibility: 150.0
      learning_rate: 0.01
    # --- ▼ 修正 ▼ ---
    probabilistic_neuron: # 確率的ニューロン用の新しいセクション
      tau_mem: 20.0       # デフォルト値
      threshold: 1.0      # デフォルト値
      temperature: 0.5    # デフォルト値
      noise_intensity: 0.0 # デフォルト値
    # --- ▲ 修正 ▲ ---
    probabilistic_hebbian: # 確率的ヘブ学習用の新しいセクション
      learning_rate: 0.002
      weight_decay: 0.00005 # 重み減衰

  self_supervised:
    learning_rate: 0.0008
    use_scheduler: true
    grad_clip_norm: 1.0
    warmup_epochs: 1
    use_amp: true
    loss:
      prediction_weight: 0.0     # TCL導入のため、従来の損失の重みを0に設定
      spike_reg_weight: 0.01
      sparsity_reg_weight: 0.0
      mem_reg_weight: 0.0000001
      tcl_weight: 1.0            # Temporal Contrastive Lossの重み
      tcl_temperature: 0.1       # TCLの温度パラメータ

  physics_informed:
    learning_rate: 0.0005
    use_scheduler: true
    grad_clip_norm: 1.0
    warmup_epochs: 1
    use_amp: true
    loss:
      ce_weight: 1.0
      spike_reg_weight: 0.01
      mem_smoothness_weight: 0.001

  probabilistic_ensemble:
    learning_rate: 0.0007
    use_scheduler: true
    grad_clip_norm: 1.0
    warmup_epochs: 1
    use_amp: true
    loss:
      ce_weight: 1.0
      variance_reg_weight: 0.1


  log_dir: "runs/snn_experiment"
  eval_interval: 1
  log_interval: 1

model_registry:
  provider: "file"
  file:
    path: "runs/model_registry.json"
  redis:
    host: localhost
    port: 6379
    db: 0

app:
  server_name: "127.0.0.1"
  server_port: 7860
  max_len: 100