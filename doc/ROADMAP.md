# **SNN5 高度化ロードマップ (v10.5): 戦略的トラックの明確化と修正容易性の実装**

## **I. 基本方針 (v10.5 更新)**

Objective.md \[cite: SNN5-a46fee70a6f8840d571935dbe79d8df57f7c2169/doc/Objective.md\] で定義された核心目標、特に「**④ 非GPU依存**」「**⑤ 非勾配型学習システム**」「**⑥ 修正可能なAI**」の達成を最優先事項とします。

「LLMの事後修正技術」\[cite: SNN5-a46fee70a6f8840d571935dbe79d8df57f7c2169/doc/レポート：LLMの事後修正技術と修正容易設計に関する技術的サーベイ.md\] および「ANN-SNN変換情報」\[cite: SNN5-a46fee70a6f8840d571935dbe79d8df57f7c2169/doc/レポート：ANN-SNN変換情報.md\] の分析に基づき、プロジェクトSNN5は、学習パラダイムを以下の3つの戦略的トラックに分離・定義します。

1. **【本流】生物学的パラダイム (Bio / LNN Track):** \* **目的:** Objective.mdの目標④, ⑤, ⑥を達成する、プロジェクトの**最重要トラック**。  
   * **技術:** Liquid Neural Network (LNN) の原理と、局所的な可塑性ルール（STDP, R-STDP, BCM等）に基づく微分フリー学習則を用います。  
   * **展開:** ニューロモーフィック・ハードウェア（Loihi 2, SpiNNaker）上での「オンチップ学習」と「継続的適応」を最終目標とします。  
2. **【戦略トラックA】ANN-SNN変換 (SFN / MoE Track):** \* **目的:** Objective.mdの目標①（高精度 ≥96%）および②（高効率 ≤1/50）を最短で達成し、かつ「LLM修正技術レポート」\[cite: SNN5-a46fee70a6f8840d571935dbe79d8df57f7c2169/doc/レポート：LLMの事後修正技術と修正容易設計に関する技術的サーベイ.md\]で示された\*\*アーキテクチャレベルでの修正容易性（目標⑥）\*\*を実現します。  
   * **技術:** SOTAのANN（Llama 4アーキテクチャ）をベースとし、「**Spiking MoE (SEMM)**」\[30\]、「**SNN-RMSNorm**」\[33\]、「**SNN-SwiGLU**」\[33\]など、SNN親和性の高いコンポーネントをフルカスタム実装します。「SFN」\[26\]によるT=1変換もこのトラックに含まれます。  
   * **展開:** GPU（推論用）またはニューロモーフィック・ハードウェア（推論用）。  
3. **【戦略トラックB】代理勾配 (SG Track):** \* **目的:** SNN固有の「時間的学習能力」を最大化し、\*\*動的タスク（時系列、DVS、音声）\*\*におけるSOTA精度を目指します。また、Bio Trackのメタ学習（SOTAリサーチ 3.3節）の基盤としても機能します。  
   * **技術:** 代理勾配（Surrogate Gradient: SG）法による直接訓練。  
   * **展開:** GPU（訓練・推論）またはニューロモーフィック・ハードウェア（推論用）。

## **II. 実装ロードマップ (v10.5)**

### **フェーズ1: 高精度アーキテクチャの分岐実装 (All Tracks)**

| ID | タスク | 概要 | 担当トラック | SOTA技術 | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P1.1** | **深層残差SNNの実装** | 勾配消失を防ぐ残差接続を実装する。 | **SG Track** | **SEW-ResNet** \[9\] | 計画中 |
| **P1.2** | **SOTAコンポーネント実装 (Transformer)** | **「SOTAツーリング・ギャップ」\[cite: SNN5-a46fee70a6f8840d571935dbe79d8df57f7c2169/doc/レポート：ANN-SNN変換情報.md\]解消のため、"BrainTransformers" \[33\] に基づく SNN-RMSNorm、SNN-SwiGLU、および近似 SNN-RoPE \[35, 59\] のフルカスタム実装を行う。** | **SG / SFN** | SNN-RMSNorm \[33\], SNN-RPE \[35\] | **計画中** |
| **P1.3** | **ハイブリッド・アーキテクチャ戦略** | \*\*iRoPE \[13\] や QK-norm \[9\] など変換リスクが極めて高い演算（SOTAリサーチ IV.D.2）をANNドメインに残し、\*\*計算負荷の大きいFFN/MoEのみをSNN化するハイブリッド戦略（hybrid\_transformer.py）を実装・検証する。 | **SG Track** | Hybrid-SNN \[cite: SNN5-a46fee70a6f8840d571935dbe79d8df57f7c2169/snn\_research/architectures/hybrid\_transformer.py\] | **計画中** |
| **P1.4** | **時空間アテンション** | SNN固有の時間情報を活用するため、スパイクベースの時空間アテンション・モジュールを実装する。 | **SG Track** | DTA-SNN \[10\], STAA-SNN \[11\] | 計画中 |
| **P1.5** | **SFN変換パイプラインの構築** | 高性能ANN (ViT等) を訓練し、T=1のSNNに変換するパイプラインを構築する。 | **SFN Track** | **SFN** \[26\], **SFormer** \[27\] | 計画中 |
| **P1.6** | **Spiking MoE の実装 (最重要)** | Llama 4 の MoE アーキテクチャをSNNに実装する。**NIPS 2024で発表された「SEMM」 \[30\]** に基づき、乗算不要のスパイクベース・ルーティング機構を実装する。 | **SG / SFN** | **SEMM** \[30\] | **計画中** |

### **フェーズ2: ニューロン・ダイナミクスと堅牢性の強化 (All Tracks)**

| ID | タスク | 概要 | SOTA技術 | 参照(強化案) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P2.1** | **学習可能な動的ニューロン (EL)** | P2.1 (PLIF) / P2.2 (GLIF) を拡張し、膜時定数($\\tau$)が入力依存で動的に進化する「Evolutionary Leak (EL)」機構を実装する。 | **FEEL-SNN (EL)** \[47\] | 3.1, SOTAリサーチ 2.2節 | 計画中 |
| **P2.2** | **堅牢な周波数エンコーディング (FE)** | P2.3 (TTFS移行) に加え、ノイズ周波数帯をフィルタリングする「Frequency Encoding (FE)」を実装する。 | **FEEL-SNN (FE)** \[47\] | 3.2, SOTAリサーチ 2.2節 | 計画中 |
| **P2.3** | **時間コーディングの最適化** | レートコーディングから、高速・高効率なTTFS（Time-to-First-Spike）コーディングへ移行する。 | **TTFS** \[30, 84\] | 3.2 | 計画中 |

### **フェーズ3: SOTAモデルのHPOチューニング (All Tracks)**

| ID | タスク | 概要 | SOTA技術 | 関連(SNN5) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P3.1** | **戦略的HPO (SG/Bio Track)** | **(SG/SFN Track)** P1で実装したモデル（Spikingformer, SEMM）の精度を最大化する。 **(Bio Track)** 3因子学習ルール（R-STDP）等のハイパーパラメータをGPU上で事前最適化する（メタ学習）。 | **Optuna**, **メタ学習** \[41\] | run\_hpo.py | 計画中 |

### **フェーズ4: 省エネ化（エネルギー効率）の徹底追求 (SG / SFN Tracks)**

| ID | タスク | 概要 | SOTA技術 | 参照(強化案) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P4.1** | **スパース性正則化** | 損失関数にスパイク率ペナルティを導入し、スパースな発火（省エネ）を強制する。 | スパース性正則化 \[12, 13\] | 4.2 | 計画中 |
| **P4.2** | **量子化アウェア学習 (QAT)** | 2ビットや4ビットなどの低ビット精度で学習・推論を行い、メモリと演算コストを劇的に削減する。 | **QUEST** \[14\] | 4.3 | 計画中 |
| **P4.3** | **ワンショット・プルーニング** | ヘッセ行列（SBC/OBC）に基づき再学習不要でネットワークを剪定し、開発サイクルを高速化する。 | **SBC** \[15\] | 4.4 | 計画中 |

### **フェーズ5: ニューロモーフィック・デプロイメント (All Tracks)**

| ID | タスク | 概要 | SOTA技術 | 参照(強化案) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P5.1** | **動的推論 (SNN Cutoff)** | 推論の途中で確信度を監視し、早期終了させレイテンシを動的に削減する。 | **SNN Cutoff** \[16, 58\] | 6.1 | 計画中 |
| **P5.2** | **HW協調設計 (Lava)** | **(SG/SFN Track)** P1/P4の最適化済モデルを推論用にLoihi 2へ移植する。 **(Bio Track)** P8で実装したR-STDP学習則をLoihi 2に移植し、「**オンチップ学習**」を実行する。 | **Lava Framework** \[61, 39\] | 6.2, SOTAリサーチ 3.3節 | 計画中 |
| **P5.3** | **HW協調設計 (SpiNNaker)** | P1/P4/P8のモデルをSpiNNaker向けのsPyNNakerフレームワークへ移植する。 | **sPyNNaker** \[69\] | 6.2 | 計画中 |

### **フェーズ6: 統合的効率化検証 (SG / SFN Tracks)**

| ID | タスク | 概要 | SOTA技術 | 関連(SNN5) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P6.1** | **統合効率化モデルの構築** | P3でチューニングしたSG/SFNモデルに対し、P2.3 (TTFS), P4 (省エネ化), P5.1 (SNN Cutoff) の技術を**すべて適用**した最終モデルを構築する。 | 複合技術 | pruning.py, quantization.py, deployment.py | 計画中 |
| **P6.2** | **最終効率ベンチマーク** | P6.1で構築した「最終モデル」を P7.3 (SNNBench) で評価し、精度と消費電力（SynOps）を測定。ANN比1/50の目標達成度を最終判定する。 | **SNNBench** \[79\] | run\_benchmark\_suite.py | 計画中 |

### **フェーズ7: ベンチマークと基盤整備 (All Tracks)**

| ID | タスク | 概要 | SOTA技術 | 参照(強化案) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P7.1 (最優先)** | **開発基盤の移行 (SpikingJelly)** | P5.2 (Lava展開) へのパスを持ち、かつ「SOTAツーリング・ギャップ」を解消するための**フルカスタム・コンポーネント (P1.2, P1.6) を実装する標準基盤**として、**SpikingJelly**を最優先で採用・移行する。 | **SpikingJelly** \[24, 67\] | 7.1, SOTAリサーチ 3.2節 | **最優先** |
| **P7.2** | **ニューロモーフィック・データセット対応** | SG Trackの評価のため、CIFAR10-DVS, SHD, N-Caltech101 等のイベントベースデータセットを標準でサポートする。 | DVS/SHD Datasets \[74\] | 7.1 | 計画中 |
| **P7.3** | **統合ベンチマークの確立** | 評価指標として「精度」「SynOps（消費電力）」「スパイクレート」に加え、「**時間反転テスト**」（SOTAリサーチ 1.1節）を追加し、真の時間的学習能力を検証する。 | **SNNBench** \[79\] | 7.1, SOTAリサーチ 1.1節 | 計画中 |

### **フェーズ8: 生物学的パラダイムの強化 (Bio / LNN Track \- 本流)**

| ID | タスク | 概要 | 参照コード | 関連(SNN5) | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P8.1 (強化)** | **LNN/リザバー・コンピューティング実装** | LNN\_RSNN\_design\_spec.md に基づき、(STDP訓練リザバー \+ 線形リードアウト) というLSM/LNNベースラインを PyTorch で実装し、SpikingSSM 等の性能と比較する。 | prototype\_rsnn.py | spiking\_ssm.py | 計画中 |
| **P8.2** | **E/Iバランスの実装** | デールの法則（E/I分離）を snn\_research/bio\_models/simple\_network.py に正式に実装し、学習の安定性を評価する。 | rsnn\_experiments\_fixed.py | simple\_network.py | 計画中 |
| **P8.3** | **恒常性（適応的閾値）の実装** | LNN\_RSNN\_design\_spec.md (5.ダイナミクス制御) に基づき、適応的発火閾値による恒常性維持メカニズムを BioSNN に実装し、BCMLearningRule と比較検証する。 | rsnn\_experiments\_fixed.py | bcm\_rule.py | 計画中 |
| **P8.4** | **Bio Track 再現性の安定化** | 目標③(再現性95%)のため、Bio Trackの確率的挙動を分析し、シード値固定や決定論的STDPの実装検討により学習の再現性を確保する計画を策定する。 | prototype\_rsnn.py | learning\_rules/stdp.py | 計画中 |
| **P8.5** | **3因子学習則のLoihi 2実装** | SOTAリサーチ 1.3節に基づき、R-STDP学習則をLavaフレームワークで実装し、P5.2と連携して「**オンチップ学習**」を実現する。 | (SOTAリサーチ 39\) | reward\_modulated\_stdp.py | 計画中 |
| **P8.6** | **減衰付きHebbianルールの実装** | LNN\_RSNN\_design\_spec.md (4.1 局所更新ルール) で提案されたシンプルな減衰付きヘブ則（$\\Delta w \= \\eta (s\\\_i \* s\\\_j \- \\beta\*w)$）を実装し、ProbabilisticHebbian と性能・安定性を比較検証する。 | (LNN\_RSNN\_design\_spec.md) | probabilistic\_hebbian.py | 計画中 |

### **フェーズ9: 修正可能AIの運用戦略 (MoE / Bio Tracks) \[新設\]**

| ID | タスク | 概要 | 担当トラック | SOTA技術 | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P9.1** | **RAG \+ SNN 統合** | RAGSystem（外部知識）をSNN-MoEモデルと連携させ、内部知識を変更せずにリアルタイムな情報更新を実現する（低侵襲的修正）。\[cite: 3\] | **MoE / Bio** | **RAG** \[3\] | **計画中** |
| **P9.2** | **SNNエキスパートの交換 (frankenMoEs)** | 「LLM修正技術レポート」(6.3) の "frankenMoEs" \[15\] に倣い、個別に訓練したSNNエキスパートを SEMM \[30\] ルーターで「マージ」し、低コストで機能交換するパイプラインを検証する。 | **MoE Track** | **MoE** \[13\], **SEMM** \[30\] | **計画中** |
| **P9.3** | **PEFT / LoRA on SNN** | SNN-MoEの特定のエキスパート、または Bio/LNN モデルに対し、PEFT (LoRA) \[5\] を適用し、ベースモデルを破壊せずにタスク適応させる手法を検証する。 | **MoE / Bio** | **PEFT (LoRA)** \[5\] | **計画中** |
| **P9.4** | **高侵襲的修正のリスク検証** | モデル編集 (ROME \[8\]) と機械学習の忘却 (Unlearning \[2\]) をSNNで実装し、その有効性と「モデル崩壊」\[10\]や「付随的忘却」\[2\]のリスクを評価する。 | **SG / SFN** | **ROME/MEMIT** \[6\], **Unlearning** \[2\] | **計画中** |

### **フェーズ10: マルチエージェント協調の効率化 (STRMAC統合) \[新設\]**

**論文「Optimal-Agent-Selection: State-Aware Routing Framework for Efficient Multi-Agent Collaboration」\[cite: 1.1\]に基づき、自律エージェント層の効率とロバスト性を根本的に強化する。**

| ID | タスク | 概要 | 担当トラック | SOTA技術 | ステータス |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **P10.1 (最優先)** | **状態認識ルーティングの実装** | **自律エージェントの専門家選択**（AutonomousAgent.find\_expert）を、現在のシステム状態（メモリ、過去の行動結果）のベクトル符号化に基づき、最も適した専門家SNNを動的に選択するロジックに置き換える。 | **Bio / MoE** | **STRMAC** \[1.1\], コサイン類似度 | **計画中** |
| **P10.2 (重要)** | **自己進化型データ生成の統合** | SelfEvolvingAgentの進化サイクルに、STRMACの「効率的なデータ生成」アプローチを統合し、HSEO探索などのコストのかかる試行を、成功確率の高いパスに絞り込む。 | **Bio Track** | **STRMAC** \[1.1\], HSEO | 計画中 |
| **P10.3** | **マルチエージェント協調の検証** | 失敗したタスクを協力者に再割り当てする EmergentSystem のロジックを、P10.1で強化されたルーティングに基づき検証する。 | **Bio / SG** | STRMAC/Emergent | 計画中 |

*(引用文献は SNN5プロジェクトの技術的解決策リサーチ.md \[cite: SNN5-a46fee70a6f8840d571935dbe79d8df57f7c2169/doc/SNN5プロジェクトの技術的解決策リサーチ.md\] および LLMの事後修正技術...md \[cite: SNN5-a46fee70a6f8840d571935dbe79d8df57f7c2169/doc/レポート：LLMの事後修正技術と修正容易設計に関する技術的サーベイ.md\] を参照。STRMACの引用は\[cite: 1.1\]、\[cite: 1.2\]を参照。)*
